{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7ddd66ba818a452f960fde3c52467c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94323d6c0617440d80dc36f0a3626985",
              "IPY_MODEL_6d7cd5308bbc4aeea3dbe0e4a4563ca9",
              "IPY_MODEL_daf02100154442a9be3383d736402f83"
            ],
            "layout": "IPY_MODEL_0198a22d3e7648f79af6cc0da2b8df72"
          }
        },
        "94323d6c0617440d80dc36f0a3626985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33c2e2348be34460b4973cc389ce2b93",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b3948fe26274425e885b04fd3f3977c6",
            "value": "Loading‚Äáweights:‚Äá100%"
          }
        },
        "6d7cd5308bbc4aeea3dbe0e4a4563ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_232d0768ec124b139c8c3de7b757c9d3",
            "max": 338,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_069c703a6f204f3f956c41b4f756afa7",
            "value": 338
          }
        },
        "daf02100154442a9be3383d736402f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99b11eb6aedc4ce5b98bc925654c8561",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c6f236e913c74e3a933462abb6d9bf0b",
            "value": "‚Äá338/338‚Äá[00:14&lt;00:00,‚Äá18.36it/s,‚ÄáMaterializing‚Äáparam=model.norm.weight]"
          }
        },
        "0198a22d3e7648f79af6cc0da2b8df72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33c2e2348be34460b4973cc389ce2b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3948fe26274425e885b04fd3f3977c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "232d0768ec124b139c8c3de7b757c9d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "069c703a6f204f3f956c41b4f756afa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99b11eb6aedc4ce5b98bc925654c8561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6f236e913c74e3a933462abb6d9bf0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cUx4ewbAZaS",
        "outputId": "90b82220-65ea-4c9d-9301-cad83a3f984d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.27.1-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.17.0)\n",
            "Collecting langchain-text-splitters\n",
            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.13.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-text-splitters) (1.2.9)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.6.9)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (9.1.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.32.4)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.5.0)\n",
            "Downloading pymupdf-1.27.1-cp310-abi3-manylinux_2_28_x86_64.whl (24.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
            "Installing collected packages: pymupdf, langchain-text-splitters\n",
            "Successfully installed langchain-text-splitters-1.1.0 pymupdf-1.27.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf pandas openai langchain-text-splitters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "E05alo60HByT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # UPSC Newspaper Analysis Pipeline - LangChain Enhanced Version\n",
        "# # Using LangChain's RecursiveCharacterTextSplitter for semantic chunking\n",
        "\n",
        "# import fitz  # PyMuPDF\n",
        "# import pandas as pd\n",
        "# import json\n",
        "# import time\n",
        "# import re\n",
        "# from google.colab import files\n",
        "# from google.colab import userdata\n",
        "# from openai import OpenAI\n",
        "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# # --- CONFIGURATION ---\n",
        "# OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "# CHUNK_SIZE = 1000  # Characters (LangChain works with characters, not words)\n",
        "# CHUNK_OVERLAP = 100  # Characters - overlap for context continuity\n",
        "# MODEL = \"gpt-4o\"\n",
        "\n",
        "# def clean_text(text):\n",
        "#     \"\"\"Clean and normalize extracted text.\"\"\"\n",
        "#     # Remove excessive whitespace\n",
        "#     text = re.sub(r'\\s+', ' ', text)\n",
        "#     # Remove page numbers and headers/footers patterns\n",
        "#     text = re.sub(r'\\b\\d+\\s*\\|\\s*\\w+\\b', '', text)\n",
        "#     # Remove multiple dots\n",
        "#     text = re.sub(r'\\.{3,}', '...', text)\n",
        "#     return text.strip()\n",
        "\n",
        "# def extract_text_from_pdfs(uploaded_files):\n",
        "#     \"\"\"Enhanced PDF text extraction with cleaning.\"\"\"\n",
        "#     all_text = []\n",
        "\n",
        "#     for filename, content in uploaded_files.items():\n",
        "#         print(f\"\\n{'='*60}\")\n",
        "#         print(f\"üìÑ Processing: {filename}\")\n",
        "#         print(f\"{'='*60}\")\n",
        "\n",
        "#         try:\n",
        "#             doc = fitz.open(stream=content, filetype=\"pdf\")\n",
        "#             page_count = len(doc)\n",
        "#             pdf_text = \"\"\n",
        "\n",
        "#             for page_num in range(page_count):\n",
        "#                 page = doc[page_num]\n",
        "#                 page_text = page.get_text(\"text\", sort=True)\n",
        "#                 pdf_text += page_text + \"\\n\"\n",
        "\n",
        "#                 if (page_num + 1) % 10 == 0:\n",
        "#                     print(f\"  ‚Üí Processed {page_num + 1}/{page_count} pages...\")\n",
        "\n",
        "#             doc.close()\n",
        "\n",
        "#             # Clean the extracted text\n",
        "#             pdf_text = clean_text(pdf_text)\n",
        "\n",
        "#             all_text.append({\n",
        "#                 'filename': filename,\n",
        "#                 'text': pdf_text,\n",
        "#                 'pages': page_count,\n",
        "#                 'word_count': len(pdf_text.split())\n",
        "#             })\n",
        "\n",
        "#             print(f\"‚úì Extracted {page_count} pages ({len(pdf_text.split())} words)\")\n",
        "\n",
        "#         except Exception as e:\n",
        "#             print(f\"‚ùå Error processing {filename}: {e}\")\n",
        "\n",
        "#     return all_text\n",
        "\n",
        "# def create_langchain_chunks(text, source_filename):\n",
        "#     \"\"\"\n",
        "#     Use LangChain's RecursiveCharacterTextSplitter for intelligent chunking.\n",
        "#     This splits on paragraph boundaries, then sentences, then words - preserving semantic coherence.\n",
        "#     \"\"\"\n",
        "#     # Initialize LangChain's text splitter\n",
        "#     text_splitter = RecursiveCharacterTextSplitter(\n",
        "#         chunk_size=CHUNK_SIZE,\n",
        "#         chunk_overlap=CHUNK_OVERLAP,\n",
        "#         length_function=len,\n",
        "#         separators=[\n",
        "#             \"\\n\\n\",  # Split on paragraphs first\n",
        "#             \"\\n\",    # Then on line breaks\n",
        "#             \". \",    # Then on sentences\n",
        "#             \", \",    # Then on clauses\n",
        "#             \" \",     # Finally on words\n",
        "#             \"\"       # Last resort: character level\n",
        "#         ],\n",
        "#         is_separator_regex=False\n",
        "#     )\n",
        "\n",
        "#     # Create chunks using LangChain\n",
        "#     chunks = text_splitter.create_documents(\n",
        "#         texts=[text],\n",
        "#         metadatas=[{\"source\": source_filename}]\n",
        "#     )\n",
        "\n",
        "#     # Convert LangChain Document objects to our format\n",
        "#     formatted_chunks = []\n",
        "#     for idx, chunk in enumerate(chunks):\n",
        "#         formatted_chunks.append({\n",
        "#             'text': chunk.page_content,\n",
        "#             'source': source_filename,\n",
        "#             'chunk_position': idx,\n",
        "#             'word_count': len(chunk.page_content.split()),\n",
        "#             'char_count': len(chunk.page_content)\n",
        "#         })\n",
        "\n",
        "#     return formatted_chunks\n",
        "\n",
        "# def call_gpt4o_for_upsc(chunk_id, text_chunk, source_file, client):\n",
        "#     \"\"\"Enhanced GPT-4o call with better prompt for quality crux.\"\"\"\n",
        "#     system_prompt = \"\"\"\n",
        "# You are a UPSC CSE Mains examiner creating a high-quality study database.\n",
        "\n",
        "# STRICT ANALYSIS CRITERIA:\n",
        "# 1. ONLY extract content with clear UPSC Mains relevance\n",
        "# 2. Each entry must have policy/governance/constitutional/ethical/economic implications\n",
        "# 3. Must be mappable to specific GS1-GS4 syllabus topics\n",
        "# 4. Must have potential for 10/15-mark analytical questions\n",
        "\n",
        "# REJECTION CRITERIA (mark as irrelevant):\n",
        "# ‚ùå Celebrity news, entertainment, sports scores\n",
        "# ‚ùå Simple factual updates without analytical depth\n",
        "# ‚ùå Advertisements, promotional content\n",
        "# ‚ùå Routine appointments without policy significance\n",
        "# ‚ùå Local incidents without systemic lessons\n",
        "# ‚ùå Generic news headlines without deeper implications\n",
        "\n",
        "# ACCEPTANCE CRITERIA (mark as relevant):\n",
        "# ‚úì Policy announcements with governance implications\n",
        "# ‚úì Court judgments on constitutional matters\n",
        "# ‚úì Economic reforms/fiscal measures\n",
        "# ‚úì International relations developments\n",
        "# ‚úì Social issues with ethical dimensions\n",
        "# ‚úì Environmental/scientific developments with policy impact\n",
        "# ‚úì Governance case studies (success/failure)\n",
        "\n",
        "# CRUX WRITING RULES (CRITICAL):\n",
        "# The \"cruz\" field must follow this EXACT structure:\n",
        "\n",
        "# **What happened:** [2-3 sentences: Clearly state the NEWS EVENT/DEVELOPMENT from the article - be specific with facts, names, dates, numbers, court names, policy names, etc.]\n",
        "\n",
        "# **Static concept:** [1-2 sentences: Identify the UPSC syllabus topic this connects to - mention specific GS paper topic like \"Article 21\", \"Monetary Policy\", \"Cooperative Federalism\", etc.]\n",
        "\n",
        "# **Why it matters for UPSC:** [2-3 sentences: Explain how this can be asked in Mains - what analytical angle, what debate it raises, what examples it provides for answers]\n",
        "\n",
        "# **Possible question angle:** [1 sentence: Suggest a potential Mains question format]\n",
        "\n",
        "# EXAMPLE OF GOOD CRUX:\n",
        "# \"**What happened:** The Supreme Court ruled that the Electoral Bond Scheme violates Article 19(1)(a) (freedom of speech) and citizens' right to information under Article 19(1)(a). The court ordered SBI to disclose all donor details to the Election Commission by March 2024.\n",
        "\n",
        "# **Static concept:** This relates to GS2 topics: transparency in political funding, Right to Information, Article 19 fundamental rights, and election reforms.\n",
        "\n",
        "# **Why it matters for UPSC:** This judgment is crucial for questions on electoral reforms, transparency in governance, and balancing privacy vs. public interest. It provides a recent Supreme Court precedent for RTI-related questions and can be used as a case study in answers about political finance regulation.\n",
        "\n",
        "# **Possible question angle:** 'The Supreme Court's verdict on Electoral Bonds has reignited the debate on transparency in political funding. Critically analyze the judgment's implications for democratic accountability.'\"\n",
        "\n",
        "# RETURN FORMAT:\n",
        "# Return JSON with key 'items' containing ONE object per distinct news story/theme:\n",
        "# {\n",
        "#   \"items\": [\n",
        "#     {\n",
        "#       \"relevant\": true/false,\n",
        "#       \"gs_paper\": \"GS1\" or \"GS2\" or \"GS3\" or \"GS4\" or \"Not Applicable\",\n",
        "#       \"syllabus_topic\": \"Specific syllabus line\" or \"Not Applicable\",\n",
        "#       \"cruz\": \"Follow the structure above\" or \"Not Applicable\"\n",
        "#     }\n",
        "#   ]\n",
        "# }\n",
        "\n",
        "# If relevant = false:\n",
        "# - gs_paper = \"Not Applicable\"\n",
        "# - syllabus_topic = \"Not Applicable\"\n",
        "# - cruz = \"Not Applicable\"\n",
        "\n",
        "# IMPORTANT:\n",
        "# - Extract ONLY distinct news stories (don't repeat same story multiple times)\n",
        "# - If chunk contains multiple distinct UPSC-relevant stories, create separate items\n",
        "# - If chunk is repetitive text or contains no new info, return single item with relevant=false\n",
        "# \"\"\"\n",
        "\n",
        "#     try:\n",
        "#         response = client.chat.completions.create(\n",
        "#             model=MODEL,\n",
        "#             messages=[\n",
        "#                 {\"role\": \"system\", \"content\": system_prompt},\n",
        "#                 {\"role\": \"user\", \"content\": f\"Source: {source_file}\\n\\nAnalyze this newspaper chunk:\\n\\n{text_chunk}\"}\n",
        "#             ],\n",
        "#             response_format={\"type\": \"json_object\"},\n",
        "#             temperature=0.2\n",
        "#         )\n",
        "#         return json.loads(response.choices[0].message.content)\n",
        "#     except Exception as e:\n",
        "#         print(f\"  ‚ùå API Error on chunk {chunk_id}: {e}\")\n",
        "#         return {\"items\": []}\n",
        "\n",
        "# def save_extracted_text(pdf_data):\n",
        "#     \"\"\"Save concatenated text from all PDFs to a file for review.\"\"\"\n",
        "#     combined_text = \"\"\n",
        "#     for pdf in pdf_data:\n",
        "#         combined_text += f\"\\n\\n{'='*80}\\n\"\n",
        "#         combined_text += f\"SOURCE: {pdf['filename']}\\n\"\n",
        "#         combined_text += f\"PAGES: {pdf['pages']} | WORDS: {pdf['word_count']}\\n\"\n",
        "#         combined_text += f\"{'='*80}\\n\\n\"\n",
        "#         combined_text += pdf['text']\n",
        "\n",
        "#     with open('extracted_text_all_pdfs.txt', 'w', encoding='utf-8') as f:\n",
        "#         f.write(combined_text)\n",
        "\n",
        "#     print(f\"\\n‚úì Saved extracted text to: extracted_text_all_pdfs.txt\")\n",
        "#     return 'extracted_text_all_pdfs.txt'\n",
        "\n",
        "# # --- MAIN EXECUTION ---\n",
        "# def main():\n",
        "#     client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "#     print(\"=\"*80)\n",
        "#     print(\" \"*15 + \"UPSC NEWSPAPER ANALYSIS PIPELINE (LangChain)\")\n",
        "#     print(\"=\"*80)\n",
        "#     print(\"\\nüì§ Upload your newspaper PDFs (multiple files supported)\")\n",
        "#     print(\"-\"*80)\n",
        "\n",
        "#     uploaded = files.upload()\n",
        "\n",
        "#     if not uploaded:\n",
        "#         print(\"\\n‚ùå No files uploaded. Exiting...\")\n",
        "#         return\n",
        "\n",
        "#     print(f\"\\n‚úì {len(uploaded)} file(s) uploaded successfully\\n\")\n",
        "\n",
        "#     # Extract text from all PDFs\n",
        "#     pdf_data = extract_text_from_pdfs(uploaded)\n",
        "\n",
        "#     if not pdf_data:\n",
        "#         print(\"\\n‚ùå No text could be extracted. Exiting...\")\n",
        "#         return\n",
        "\n",
        "#     # Save extracted text for review\n",
        "#     text_file = save_extracted_text(pdf_data)\n",
        "#     files.download(text_file)\n",
        "\n",
        "#     # Create chunks from all PDFs using LangChain\n",
        "#     print(f\"\\n{'='*80}\")\n",
        "#     print(f\"üîÑ CREATING SEMANTIC CHUNKS WITH LANGCHAIN\")\n",
        "#     print(f\"{'='*80}\")\n",
        "#     print(f\"Chunk size: {CHUNK_SIZE} characters\")\n",
        "#     print(f\"Overlap: {CHUNK_OVERLAP} characters\")\n",
        "#     print(f\"{'='*80}\\n\")\n",
        "\n",
        "#     all_chunks = []\n",
        "#     for pdf in pdf_data:\n",
        "#         if pdf['text'].strip():\n",
        "#             print(f\"Processing {pdf['filename']}...\")\n",
        "#             pdf_chunks = create_langchain_chunks(pdf['text'], pdf['filename'])\n",
        "#             all_chunks.extend(pdf_chunks)\n",
        "\n",
        "#             # Calculate average chunk size\n",
        "#             avg_words = sum(c['word_count'] for c in pdf_chunks) / len(pdf_chunks) if pdf_chunks else 0\n",
        "#             avg_chars = sum(c['char_count'] for c in pdf_chunks) / len(pdf_chunks) if pdf_chunks else 0\n",
        "\n",
        "#             print(f\"‚úì Created {len(pdf_chunks)} semantic chunks\")\n",
        "#             print(f\"  Average: {avg_words:.0f} words ({avg_chars:.0f} characters) per chunk\\n\")\n",
        "\n",
        "#     if not all_chunks:\n",
        "#         print(\"\\n‚ùå No chunks created. Exiting...\")\n",
        "#         return\n",
        "\n",
        "#     print(f\"\\n{'='*80}\")\n",
        "#     print(f\"üìä PROCESSING SUMMARY\")\n",
        "#     print(f\"{'='*80}\")\n",
        "#     print(f\"Total PDFs: {len(pdf_data)}\")\n",
        "#     print(f\"Total chunks to analyze: {len(all_chunks)}\")\n",
        "#     print(f\"Model: {MODEL}\")\n",
        "#     print(f\"Chunking: LangChain RecursiveCharacterTextSplitter\")\n",
        "#     print(f\"{'='*80}\\n\")\n",
        "\n",
        "#     all_data = []\n",
        "#     relevant_count = 0\n",
        "#     irrelevant_count = 0\n",
        "\n",
        "#     # Process each chunk\n",
        "#     for idx, chunk_obj in enumerate(all_chunks):\n",
        "#         print(f\"\\n[{idx+1}/{len(all_chunks)}] Processing chunk from {chunk_obj['source']}...\")\n",
        "#         print(f\"  Words: {chunk_obj['word_count']} | Characters: {chunk_obj['char_count']}\")\n",
        "\n",
        "#         # API Call\n",
        "#         result = call_gpt4o_for_upsc(idx, chunk_obj['text'], chunk_obj['source'], client)\n",
        "\n",
        "#         items = result.get(\"items\", [])\n",
        "\n",
        "#         if not items:\n",
        "#             items = [{\n",
        "#                 \"relevant\": False,\n",
        "#                 \"gs_paper\": \"Not Applicable\",\n",
        "#                 \"syllabus_topic\": \"Not Applicable\",\n",
        "#                 \"cruz\": \"Not Applicable\"\n",
        "#             }]\n",
        "\n",
        "#         for item_idx, item in enumerate(items):\n",
        "#             is_relevant = item.get(\"relevant\", False)\n",
        "\n",
        "#             all_data.append({\n",
        "#                 \"ID\": f\"UPSC_{idx:04d}_{item_idx}_{time.strftime('%Y%m%d')}\",\n",
        "#                 \"Source PDF\": chunk_obj['source'],\n",
        "#                 \"Text Chunk\": chunk_obj['text'],\n",
        "#                 \"Chunk Word Count\": chunk_obj['word_count'],\n",
        "#                 \"Chunk Char Count\": chunk_obj['char_count'],\n",
        "#                 \"Relevant to UPSC\": is_relevant,\n",
        "#                 \"GS Paper\": item.get(\"gs_paper\", \"Not Applicable\"),\n",
        "#                 \"Syllabus Topic\": item.get(\"syllabus_topic\", \"Not Applicable\"),\n",
        "#                 \"Crux\": item.get(\"cruz\", \"Not Applicable\")\n",
        "#             })\n",
        "\n",
        "#             if is_relevant:\n",
        "#                 relevant_count += 1\n",
        "#                 preview = chunk_obj['text'][:100] + \"...\" if len(chunk_obj['text']) > 100 else chunk_obj['text']\n",
        "#                 print(f\"  ‚úì Found relevant entry: {item.get('gs_paper')} - {item.get('syllabus_topic')[:50]}...\")\n",
        "#                 print(f\"    Preview: {preview}\")\n",
        "#             else:\n",
        "#                 irrelevant_count += 1\n",
        "\n",
        "#         # Rate limiting\n",
        "#         time.sleep(1.5)\n",
        "\n",
        "#     # Create DataFrame\n",
        "#     print(f\"\\n{'='*80}\")\n",
        "#     print(f\"‚úÖ PROCESSING COMPLETE\")\n",
        "#     print(f\"{'='*80}\")\n",
        "#     print(f\"Total entries: {len(all_data)}\")\n",
        "#     print(f\"‚úì Relevant: {relevant_count}\")\n",
        "#     print(f\"‚úó Irrelevant: {irrelevant_count}\")\n",
        "#     print(f\"Relevance rate: {(relevant_count/len(all_data)*100):.1f}%\")\n",
        "#     print(f\"{'='*80}\\n\")\n",
        "\n",
        "#     if all_data:\n",
        "#         df = pd.DataFrame(all_data)\n",
        "\n",
        "#         # Summary by PDF\n",
        "#         print(\"üìë SUMMARY BY SOURCE:\")\n",
        "#         for pdf in pdf_data:\n",
        "#             pdf_entries = df[df['Source PDF'] == pdf['filename']]\n",
        "#             pdf_relevant = pdf_entries[pdf_entries['Relevant to UPSC'] == True]\n",
        "#             print(f\"  ‚Ä¢ {pdf['filename']}: {len(pdf_relevant)}/{len(pdf_entries)} relevant\")\n",
        "\n",
        "#         # Summary by GS Paper\n",
        "#         print(\"\\nüìö SUMMARY BY GS PAPER:\")\n",
        "#         gs_summary = df[df['Relevant to UPSC'] == True]['GS Paper'].value_counts()\n",
        "#         for paper, count in gs_summary.items():\n",
        "#             if paper != \"Not Applicable\":\n",
        "#                 print(f\"  ‚Ä¢ {paper}: {count} entries\")\n",
        "\n",
        "#         # Summary by Syllabus Topic (top 10)\n",
        "#         print(\"\\nüìñ TOP 10 SYLLABUS TOPICS:\")\n",
        "#         topic_summary = df[df['Relevant to UPSC'] == True]['Syllabus Topic'].value_counts().head(10)\n",
        "#         for topic, count in topic_summary.items():\n",
        "#             if topic != \"Not Applicable\":\n",
        "#                 topic_short = topic[:60] + \"...\" if len(topic) > 60 else topic\n",
        "#                 print(f\"  ‚Ä¢ {topic_short}: {count}\")\n",
        "\n",
        "#         # Save CSV\n",
        "#         output_filename = f\"upsc_dataset_langchain_{time.strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "#         df.to_csv(output_filename, index=False)\n",
        "\n",
        "#         print(f\"\\nüíæ Dataset saved: {output_filename}\")\n",
        "#         print(f\"{'='*80}\\n\")\n",
        "\n",
        "#         files.download(output_filename)\n",
        "#     else:\n",
        "#         print(\"\\n‚ö†Ô∏è  No data extracted.\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cQQP6nmhFgIp",
        "outputId": "6b4277c0-de92-406e-c1f2-a63121d4a49e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "               UPSC NEWSPAPER ANALYSIS PIPELINE (LangChain)\n",
            "================================================================================\n",
            "\n",
            "üì§ Upload your newspaper PDFs (multiple files supported)\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-503adbc0-47af-46bb-bf98-8a7bce9677e3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-503adbc0-47af-46bb-bf98-8a7bce9677e3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Bollywood-Town-February-2026.pdf to Bollywood-Town-February-2026 (4).pdf\n",
            "Saving sportstar.pdf to sportstar (3).pdf\n",
            "Saving TH Delhi 04-02-2026 (1) (2).pdf to TH Delhi 04-02-2026 (1) (2) (1).pdf\n",
            "\n",
            "‚úì 3 file(s) uploaded successfully\n",
            "\n",
            "\n",
            "============================================================\n",
            "üìÑ Processing: Bollywood-Town-February-2026 (4).pdf\n",
            "============================================================\n",
            "  ‚Üí Processed 10/40 pages...\n",
            "  ‚Üí Processed 20/40 pages...\n",
            "  ‚Üí Processed 30/40 pages...\n",
            "  ‚Üí Processed 40/40 pages...\n",
            "‚úì Extracted 40 pages (11577 words)\n",
            "\n",
            "============================================================\n",
            "üìÑ Processing: sportstar (3).pdf\n",
            "============================================================\n",
            "  ‚Üí Processed 10/53 pages...\n",
            "  ‚Üí Processed 20/53 pages...\n",
            "  ‚Üí Processed 30/53 pages...\n",
            "  ‚Üí Processed 40/53 pages...\n",
            "  ‚Üí Processed 50/53 pages...\n",
            "‚úì Extracted 53 pages (3 words)\n",
            "\n",
            "============================================================\n",
            "üìÑ Processing: TH Delhi 04-02-2026 (1) (2) (1).pdf\n",
            "============================================================\n",
            "  ‚Üí Processed 10/22 pages...\n",
            "  ‚Üí Processed 20/22 pages...\n",
            "‚úì Extracted 22 pages (43165 words)\n",
            "\n",
            "‚úì Saved extracted text to: extracted_text_all_pdfs.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c01a5966-61ef-402d-a67e-25571b8e596e\", \"extracted_text_all_pdfs.txt\", 333140)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üîÑ CREATING SEMANTIC CHUNKS WITH LANGCHAIN\n",
            "================================================================================\n",
            "Chunk size: 1000 characters\n",
            "Overlap: 100 characters\n",
            "================================================================================\n",
            "\n",
            "Processing Bollywood-Town-February-2026 (4).pdf...\n",
            "‚úì Created 82 semantic chunks\n",
            "  Average: 147 words (891 characters) per chunk\n",
            "\n",
            "Processing sportstar (3).pdf...\n",
            "‚úì Created 1 semantic chunks\n",
            "  Average: 3 words (33 characters) per chunk\n",
            "\n",
            "Processing TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "‚úì Created 306 semantic chunks\n",
            "  Average: 148 words (873 characters) per chunk\n",
            "\n",
            "\n",
            "================================================================================\n",
            "üìä PROCESSING SUMMARY\n",
            "================================================================================\n",
            "Total PDFs: 3\n",
            "Total chunks to analyze: 389\n",
            "Model: gpt-4o\n",
            "Chunking: LangChain RecursiveCharacterTextSplitter\n",
            "================================================================================\n",
            "\n",
            "\n",
            "[1/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 148 | Characters: 984\n",
            "\n",
            "[2/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 157 | Characters: 930\n",
            "\n",
            "[3/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 127 | Characters: 765\n",
            "\n",
            "[4/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 113 | Characters: 916\n",
            "\n",
            "[5/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 126 | Characters: 880\n",
            "\n",
            "[6/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 120 | Characters: 740\n",
            "\n",
            "[7/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 165 | Characters: 979\n",
            "\n",
            "[8/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 154 | Characters: 869\n",
            "\n",
            "[9/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 156 | Characters: 842\n",
            "\n",
            "[10/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 195 | Characters: 985\n",
            "\n",
            "[11/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 124 | Characters: 733\n",
            "\n",
            "[12/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 136 | Characters: 920\n",
            "\n",
            "[13/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 102 | Characters: 729\n",
            "\n",
            "[14/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 128 | Characters: 912\n",
            "\n",
            "[15/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 94 | Characters: 672\n",
            "\n",
            "[16/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 118 | Characters: 849\n",
            "\n",
            "[17/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 121 | Characters: 764\n",
            "\n",
            "[18/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 153 | Characters: 973\n",
            "\n",
            "[19/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 139 | Characters: 859\n",
            "\n",
            "[20/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 151 | Characters: 875\n",
            "\n",
            "[21/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 180 | Characters: 961\n",
            "\n",
            "[22/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 152 | Characters: 724\n",
            "\n",
            "[23/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 191 | Characters: 955\n",
            "\n",
            "[24/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 140 | Characters: 778\n",
            "\n",
            "[25/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 175 | Characters: 970\n",
            "\n",
            "[26/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 186 | Characters: 977\n",
            "\n",
            "[27/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 154 | Characters: 950\n",
            "\n",
            "[28/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 146 | Characters: 904\n",
            "\n",
            "[29/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 159 | Characters: 946\n",
            "\n",
            "[30/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 100 | Characters: 610\n",
            "\n",
            "[31/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 165 | Characters: 969\n",
            "\n",
            "[32/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 175 | Characters: 987\n",
            "\n",
            "[33/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 131 | Characters: 768\n",
            "\n",
            "[34/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 143 | Characters: 995\n",
            "\n",
            "[35/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 125 | Characters: 761\n",
            "\n",
            "[36/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 119 | Characters: 819\n",
            "\n",
            "[37/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 152 | Characters: 984\n",
            "\n",
            "[38/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 140 | Characters: 910\n",
            "\n",
            "[39/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 161 | Characters: 997\n",
            "\n",
            "[40/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 132 | Characters: 843\n",
            "\n",
            "[41/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 142 | Characters: 900\n",
            "\n",
            "[42/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 109 | Characters: 751\n",
            "\n",
            "[43/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 164 | Characters: 985\n",
            "\n",
            "[44/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 145 | Characters: 887\n",
            "\n",
            "[45/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 144 | Characters: 955\n",
            "\n",
            "[46/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 129 | Characters: 856\n",
            "\n",
            "[47/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 145 | Characters: 967\n",
            "\n",
            "[48/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 95 | Characters: 692\n",
            "\n",
            "[49/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 140 | Characters: 899\n",
            "\n",
            "[50/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 145 | Characters: 926\n",
            "\n",
            "[51/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 118 | Characters: 770\n",
            "\n",
            "[52/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 158 | Characters: 997\n",
            "\n",
            "[53/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 145 | Characters: 912\n",
            "\n",
            "[54/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 155 | Characters: 993\n",
            "\n",
            "[55/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 152 | Characters: 938\n",
            "\n",
            "[56/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 153 | Characters: 913\n",
            "\n",
            "[57/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 146 | Characters: 898\n",
            "\n",
            "[58/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 140 | Characters: 876\n",
            "\n",
            "[59/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 166 | Characters: 935\n",
            "\n",
            "[60/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 151 | Characters: 944\n",
            "\n",
            "[61/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 145 | Characters: 979\n",
            "\n",
            "[62/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 129 | Characters: 820\n",
            "\n",
            "[63/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 116 | Characters: 826\n",
            "\n",
            "[64/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 135 | Characters: 840\n",
            "\n",
            "[65/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 106 | Characters: 683\n",
            "\n",
            "[66/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 153 | Characters: 944\n",
            "\n",
            "[67/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 181 | Characters: 981\n",
            "\n",
            "[68/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 163 | Characters: 968\n",
            "\n",
            "[69/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 154 | Characters: 946\n",
            "\n",
            "[70/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 155 | Characters: 957\n",
            "\n",
            "[71/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 170 | Characters: 970\n",
            "\n",
            "[72/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 191 | Characters: 973\n",
            "\n",
            "[73/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 193 | Characters: 992\n",
            "\n",
            "[74/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 170 | Characters: 998\n",
            "\n",
            "[75/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 141 | Characters: 798\n",
            "\n",
            "[76/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 137 | Characters: 783\n",
            "\n",
            "[77/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 176 | Characters: 981\n",
            "\n",
            "[78/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 184 | Characters: 972\n",
            "\n",
            "[79/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 189 | Characters: 960\n",
            "\n",
            "[80/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 191 | Characters: 980\n",
            "\n",
            "[81/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 184 | Characters: 983\n",
            "\n",
            "[82/389] Processing chunk from Bollywood-Town-February-2026 (4).pdf...\n",
            "  Words: 131 | Characters: 739\n",
            "\n",
            "[83/389] Processing chunk from sportstar (3).pdf...\n",
            "  Words: 3 | Characters: 33\n",
            "\n",
            "[84/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 154 | Characters: 905\n",
            "  ‚úì Found relevant entry: GS2 - Federalism, Finance Commission...\n",
            "    Preview: WEDNESDAY www.thehindu.com Vol. 16 No. 29 February 4, 2026 Regd. DL(ND)-11/6110/2006-07-08 DELHI RNI...\n",
            "  ‚úì Found relevant entry: GS3 - Data Protection, Privacy...\n",
            "    Preview: WEDNESDAY www.thehindu.com Vol. 16 No. 29 February 4, 2026 Regd. DL(ND)-11/6110/2006-07-08 DELHI RNI...\n",
            "\n",
            "[85/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 147 | Characters: 909\n",
            "  ‚úì Found relevant entry: GS2 - Election Commission of India...\n",
            "    Preview: . deal will not include Khemchand Singh elected Manipur BJP Legislature sensitive sectors: Goyal Par...\n",
            "  ‚úì Found relevant entry: GS3 - International Trade...\n",
            "    Preview: . deal will not include Khemchand Singh elected Manipur BJP Legislature sensitive sectors: Goyal Par...\n",
            "\n",
            "[86/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 139 | Characters: 807\n",
            "\n",
            "[87/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 177 | Characters: 1000\n",
            "  ‚úì Found relevant entry: GS2 - India and its neighborhood- relations...\n",
            "    Preview: . ding that the details would that India would stop buy- had to speak before you deal between India ...\n",
            "\n",
            "[88/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 160 | Characters: 974\n",
            "\n",
            "[89/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 168 | Characters: 957\n",
            "\n",
            "[90/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 131 | Characters: 745\n",
            "\n",
            "[91/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 147 | Characters: 878\n",
            "\n",
            "[92/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 172 | Characters: 979\n",
            "  ‚úì Found relevant entry: GS2 - Parliament and State Legislatures ‚Äì structure, fun...\n",
            "    Preview: . serve the aspirations of the for the Chief Minister‚Äôs CONTINUED ON said on Tuesday. ¬ª Page 2 Beyon...\n",
            "\n",
            "[93/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 166 | Characters: 978\n",
            "  ‚úì Found relevant entry: GS2 - Parliament and State Legislatures - structure, fun...\n",
            "    Preview: . by the BJP and JD(S) mem- with the suspension of He said as an impartial bers, Karnataka Chief Mi-...\n",
            "\n",
            "[94/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 159 | Characters: 941\n",
            "  ‚úì Found relevant entry: GS2 - Parliamentary Procedures and Conduct of Business...\n",
            "    Preview: . PTI mentary history, on the tore the earlier Mahatma Naravane (retd). behest of the government, Ga...\n",
            "  ‚úì Found relevant entry: GS2 - Government Policies and Interventions for Developm...\n",
            "    Preview: . PTI mentary history, on the tore the earlier Mahatma Naravane (retd). behest of the government, Ga...\n",
            "\n",
            "[95/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 156 | Characters: 914\n",
            "  ‚úì Found relevant entry: GS2 - Federalism, Decentralization...\n",
            "    Preview: . Centre to immediately an- throwing paper at it. The After not being allowed to and under enormous ...\n",
            "\n",
            "[96/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 165 | Characters: 943\n",
            "\n",
            "[97/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 163 | Characters: 980\n",
            "  ‚úì Found relevant entry: GS2 - Welfare schemes for vulnerable sections of the pop...\n",
            "    Preview: . CONTINUED ON sides being a part and par- Gurjeet Singh Aujla, Hibi san from the CPI(M). Led Gandhi...\n",
            "\n",
            "[98/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 152 | Characters: 895\n",
            "  ‚úì Found relevant entry: GS1 - Urbanization, their problems and their remedies...\n",
            "    Preview: . Shivam Gupta ran a construction the chairperson of the Shahjahanabad Gupta on Tuesday on disbursal...\n",
            "  ‚úì Found relevant entry: GS2 - Welfare schemes for vulnerable sections of the pop...\n",
            "    Preview: . Shivam Gupta ran a construction the chairperson of the Shahjahanabad Gupta on Tuesday on disbursal...\n",
            "\n",
            "[99/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 168 | Characters: 971\n",
            "\n",
            "[100/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 153 | Characters: 906\n",
            "\n",
            "[101/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 152 | Characters: 882\n",
            "\n",
            "[102/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 110 | Characters: 626\n",
            "\n",
            "[103/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 148 | Characters: 881\n",
            "  ‚úì Found relevant entry: GS2 - Government policies and interventions for developm...\n",
            "    Preview: . tration number. A little la- Anil Gupta, told The Hindu ly election last year. An estimated ‚Çπ242.7...\n",
            "\n",
            "[104/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 146 | Characters: 869\n",
            "\n",
            "[105/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 144 | Characters: 785\n",
            "\n",
            "[106/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 53 | Characters: 333\n",
            "\n",
            "[107/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 134 | Characters: 865\n",
            "\n",
            "[108/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 152 | Characters: 943\n",
            "\n",
            "[109/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 149 | Characters: 962\n",
            "  ‚úì Found relevant entry: GS2 - Communalism, Secularism, and Regionalism...\n",
            "    Preview: . IAS aspirants‚Äô tary Sunil Yadav, joint se- on the campus. tion of the rustication or- ticated stud...\n",
            "\n",
            "[110/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 133 | Characters: 843\n",
            "\n",
            "[111/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 100 | Characters: 589\n",
            "\n",
            "[112/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 170 | Characters: 992\n",
            "  ‚úì Found relevant entry: GS2 - Judiciary - Structure, functioning, and conduct of...\n",
            "    Preview: . racy, rioting, destruction several injured. ‚ÄúTherefore, I Ô¨Ånd that ing to the death of three Ci- o...\n",
            "\n",
            "[113/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 148 | Characters: 856\n",
            "\n",
            "[114/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 157 | Characters: 966\n",
            "  ‚úì Found relevant entry: GS3 - Government Budgeting...\n",
            "    Preview: . The court will resume hearing arguments on Wednesday. CM A ND-NDE YK THE HINDU Wednesday, February...\n",
            "\n",
            "[115/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 159 | Characters: 995\n",
            "  ‚úì Found relevant entry: GS3 - Government Budgeting...\n",
            "    Preview: . Patel met Prime Mi- National Democrat- are ‚Äúin good shape‚Äù. nister Narendra Modi and T ic Alliance...\n",
            "\n",
            "[116/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 86 | Characters: 492\n",
            "\n",
            "[117/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 158 | Characters: 942\n",
            "  ‚úì Found relevant entry: GS3 - Government Budgeting...\n",
            "    Preview: . mar termed the State bud- kept in abeyance: RTI reply Referring to speculation during the year. Fi...\n",
            "\n",
            "[118/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 131 | Characters: 766\n",
            "  ‚úì Found relevant entry: GS2 - Government policies and interventions for developm...\n",
            "    Preview: . Mukhyamantri Mahila Roj- dence‚Äù. takes care of all sectors and has revealed that the pro- tion to ...\n",
            "\n",
            "[119/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 155 | Characters: 975\n",
            "\n",
            "[120/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 151 | Characters: 921\n",
            "\n",
            "[121/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 151 | Characters: 972\n",
            "  ‚úì Found relevant entry: GS3 - Infrastructure: Energy, Ports, Roads, Airports, Ra...\n",
            "    Preview: . People from other parties pect. Our priority is to Establishment and com- be crucial to accelerate...\n",
            "\n",
            "[122/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 98 | Characters: 593\n",
            "\n",
            "[123/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 155 | Characters: 981\n",
            "  ‚úì Found relevant entry: GS2 - Government policies and interventions for developm...\n",
            "    Preview: . NEW DELHI announced ‚ÄúWith the eÔ¨Äorts of the dissolution of the Punjab Governor Gulab Punjab Red Cr...\n",
            "  ‚úì Found relevant entry: GS1 - Social empowerment, communalism, regionalism & sec...\n",
            "    Preview: . NEW DELHI announced ‚ÄúWith the eÔ¨Äorts of the dissolution of the Punjab Governor Gulab Punjab Red Cr...\n",
            "\n",
            "[124/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 143 | Characters: 876\n",
            "  ‚úì Found relevant entry: GS2 - Government policies and interventions for developm...\n",
            "    Preview: . campaign, he said on Tues- with strict enforcement of meant for the minorities. Surjit Singh Gandh...\n",
            "  ‚úì Found relevant entry: GS2 - Welfare schemes for vulnerable sections of the pop...\n",
            "    Preview: . campaign, he said on Tues- with strict enforcement of meant for the minorities. Surjit Singh Gandh...\n",
            "\n",
            "[125/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 145 | Characters: 886\n",
            "  ‚úì Found relevant entry: GS3 - Tourism and its potential as a service sector...\n",
            "    Preview: . ‚ÄúAll mi- fare. The madrasa board and Fazilka, aimed at mobi- of making Punjab drug- nority institu...\n",
            "\n",
            "[126/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 145 | Characters: 922\n",
            "  ‚úì Found relevant entry: GS3 - Infrastructure: Energy, Ports, Roads, Airports, Ra...\n",
            "    Preview: . Earlier collected by tions. The newly opened the Indian Mountaineering peaks range in altitude Fou...\n",
            "\n",
            "[127/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 131 | Characters: 813\n",
            "\n",
            "[128/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 156 | Characters: 999\n",
            "\n",
            "[129/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 106 | Characters: 609\n",
            "\n",
            "[130/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 173 | Characters: 990\n",
            "\n",
            "[131/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 130 | Characters: 786\n",
            "\n",
            "[132/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 140 | Characters: 905\n",
            "\n",
            "[133/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 164 | Characters: 995\n",
            "\n",
            "[134/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 155 | Characters: 882\n",
            "\n",
            "[135/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 145 | Characters: 905\n",
            "  ‚úì Found relevant entry: GS2 - Electoral Reforms...\n",
            "    Preview: . earlier said 3,740 Bangla- popular food chain, Wow! Momo. The team will ing, VCK and Left party ra...\n",
            "\n",
            "[136/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 164 | Characters: 989\n",
            "  ‚úì Found relevant entry: GS2 - Electoral reforms, Role of Election Commission...\n",
            "    Preview: . Yadav said, The Hindu Bureau Samajwadi Party (SP) chief ‚ÄúWill he tell on whose side Peerzada Ashiq...\n",
            "  ‚úì Found relevant entry: GS3 - Infrastructure development, Environmental impact a...\n",
            "    Preview: . Yadav said, The Hindu Bureau Samajwadi Party (SP) chief ‚ÄúWill he tell on whose side Peerzada Ashiq...\n",
            "\n",
            "[137/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 164 | Characters: 989\n",
            "\n",
            "[138/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 170 | Characters: 983\n",
            "\n",
            "[139/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 174 | Characters: 959\n",
            "\n",
            "[140/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 172 | Characters: 962\n",
            "\n",
            "[141/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 134 | Characters: 851\n",
            "  ‚úì Found relevant entry: GS3 - Conservation, environmental pollution and degradat...\n",
            "    Preview: . Yadav lah welcomed the decision, ‚ÄúThe decision brings much- mad, a farmer from Anant- city. The ac...\n",
            "\n",
            "[142/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 162 | Characters: 978\n",
            "  ‚úì Found relevant entry: GS3 - Conservation, environmental pollution and degradat...\n",
            "    Preview: . Mr. Mohanty pointed along key nesting sites in there would be some sort Habitat of dolphins is now...\n",
            "  ‚úì Found relevant entry: GS3 - Issues related to direct and indirect farm subsidi...\n",
            "    Preview: . Mr. Mohanty pointed along key nesting sites in there would be some sort Habitat of dolphins is now...\n",
            "\n",
            "[143/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 151 | Characters: 933\n",
            "  ‚úì Found relevant entry: GS3 - Conservation, environmental pollution and degradat...\n",
            "    Preview: . trail through which ecotou- conservation eÔ¨Äorts. Babulal Marandi on Tues- ly election. But later, ...\n",
            "  ‚úì Found relevant entry: GS3 - Public Distribution System, objectives, functionin...\n",
            "    Preview: . trail through which ecotou- conservation eÔ¨Äorts. Babulal Marandi on Tues- ly election. But later, ...\n",
            "\n",
            "[144/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 152 | Characters: 903\n",
            "\n",
            "[145/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 149 | Characters: 867\n",
            "  ‚úì Found relevant entry: GS3 - Conservation, environmental pollution and degradat...\n",
            "    Preview: . Od- pur, India‚Äôs missile testing distance. Biswajit Mohanty, a wil- ditions that nesting been to p...\n",
            "\n",
            "[146/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 171 | Characters: 999\n",
            "  ‚úì Found relevant entry: GS3 - Conservation, Environmental Pollution and Degradat...\n",
            "    Preview: . Ho- rookery during the eight said: ‚ÄúThere has been am- highly sensitive places. spot,‚Äù he said. wh...\n",
            "  ‚úì Found relevant entry: GS3 - Public Distribution System, Buffer Stock and Food ...\n",
            "    Preview: . Ho- rookery during the eight said: ‚ÄúThere has been am- highly sensitive places. spot,‚Äù he said. wh...\n",
            "\n",
            "[147/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 151 | Characters: 959\n",
            "  ‚úì Found relevant entry: GS3 - Infrastructure: Energy, Ports, Roads, Airports, Ra...\n",
            "    Preview: . Published by Nirmala Lakshman and Printed by S. Ramanujam at HT Media Ltd. Plot No. 8, Udyog Vihar...\n",
            "\n",
            "[148/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 121 | Characters: 697\n",
            "  ‚úì Found relevant entry: GS3 - Infrastructure: Energy, Ports, Roads, Airports, Ra...\n",
            "    Preview: . FILE PTI building in Kolathur in Chennai on Tuesday. B. JOTHI RAMALINGAM plete Statewide RRTS net-...\n",
            "\n",
            "[149/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 160 | Characters: 975\n",
            "  ‚úì Found relevant entry: GS3 - Infrastructure: Energy, Ports, Roads, Airports, Ra...\n",
            "    Preview: . State government has ac- 2 liquor scam cases Chief Minister Stalin corded in-principle appro- Silv...\n",
            "\n",
            "[150/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 162 | Characters: 975\n",
            "\n",
            "[151/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 162 | Characters: 969\n",
            "\n",
            "[152/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 158 | Characters: 978\n",
            "\n",
            "[153/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 168 | Characters: 1000\n",
            "\n",
            "[154/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 137 | Characters: 809\n",
            "\n",
            "[155/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 115 | Characters: 702\n",
            "\n",
            "[156/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 119 | Characters: 730\n",
            "  ‚úì Found relevant entry: GS2 - Functions and responsibilities of the Union and th...\n",
            "    Preview: . Rajeev HYDERABAD The Hindu Bureau The commission will a member of the purchase VIJAYAWADA address ...\n",
            "\n",
            "[157/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 155 | Characters: 937\n",
            "  ‚úì Found relevant entry: GS2 - Government policies and interventions for developm...\n",
            "    Preview: . vasthanams to a Commis- mission of Enquiry would invited. OÔ¨Écials also in- Union Minister of State...\n",
            "\n",
            "[158/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 117 | Characters: 737\n",
            "  ‚úì Found relevant entry: GS2 - Government policies and interventions for developm...\n",
            "    Preview: . examined the report sub- ghee. cus on procedural Ô¨Çaws in The members asked about mitted by the Spe...\n",
            "\n",
            "[159/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 91 | Characters: 565\n",
            "  ‚úì Found relevant entry: GS2 - Federalism, Centre-State Relations...\n",
            "    Preview: . NIRMAL HARINDRAN Ô¨Çagged. It was subsequent- nakar Reddy, who was not low bogus dairies. 2023-24. T...\n",
            "\n",
            "[160/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 147 | Characters: 882\n",
            "  ‚úì Found relevant entry: GS3 - Health and Education...\n",
            "    Preview: . been released. Rajya Sabha speech Siddharth Kumar Singh ly inÔ¨Çux of patients. Section 94 (2) of th...\n",
            "\n",
            "[161/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 165 | Characters: 946\n",
            "\n",
            "[162/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 167 | Characters: 994\n",
            "  ‚úì Found relevant entry: GS2 - Health and Education...\n",
            "    Preview: . With World Cancer Day be highly prevalent in the cials conÔ¨Årmed that the le- year at ‚Çπ50 crore eac...\n",
            "\n",
            "[163/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 151 | Characters: 931\n",
            "\n",
            "[164/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 124 | Characters: 908\n",
            "  ‚úì Found relevant entry: GS3 - Infrastructure: Energy, Ports, Roads, Airports, Ra...\n",
            "    Preview: . decades. The struggle speech...,‚Äù he said. good sign,‚Äù said Nori Datta- earlier stages rather than...\n",
            "\n",
            "[165/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 161 | Characters: 984\n",
            "  ‚úì Found relevant entry: GS3 - Infrastructure: Energy, Ports, Roads, Airports, Ra...\n",
            "    Preview: . trade deal gives hope that the way to one where competitiveness is increasingly while India lags a...\n",
            "\n",
            "[166/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 148 | Characters: 970\n",
            "  ‚úì Found relevant entry: GS3 - Infrastructure: Energy, Ports, Roads, Airports, Ra...\n",
            "    Preview: . But China deliberately channels tonne this decade while preparing CCUS. persistent and important q...\n",
            "\n",
            "[167/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 145 | Characters: 985\n",
            "  ‚úì Found relevant entry: GS3 - Infrastructure: Energy, Ports, Roads, Airports, Ra...\n",
            "    Preview: . The gap directly aÔ¨Äects electricity. That positioning directly strengthens furnaces, pooled procur...\n",
            "\n",
            "[168/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 139 | Characters: 959\n",
            "\n",
            "[169/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 138 | Characters: 913\n",
            "  ‚úì Found relevant entry: GS3 - Infrastructure: Energy, Ports, Roads, Airports, Ra...\n",
            "    Preview: . clean and electrons across industry. In steel, Green electrons embedded in supply chains ni-deal‚Äô ...\n",
            "  ‚úì Found relevant entry: GS2 - Bilateral, regional and global groupings and agree...\n",
            "    Preview: . clean and electrons across industry. In steel, Green electrons embedded in supply chains ni-deal‚Äô ...\n",
            "\n",
            "[170/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 116 | Characters: 759\n",
            "\n",
            "[171/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 153 | Characters: 975\n",
            "  ‚úì Found relevant entry: GS3 - Infrastructure: Energy, Ports, Roads, Airports, Ra...\n",
            "    Preview: . Calcination The global race is not just electrons versus cast a shadow over its relations with Rus...\n",
            "  ‚úì Found relevant entry: GS2 - India and its neighborhood- relations...\n",
            "    Preview: . Calcination The global race is not just electrons versus cast a shadow over its relations with Rus...\n",
            "\n",
            "[172/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 159 | Characters: 968\n",
            "  ‚úì Found relevant entry: GS3 - Infrastructure: Energy, Ports, Roads, Airports, Ra...\n",
            "    Preview: . What is India‚Äôs starting line like? India has than peers. This design gives China a durable There ...\n",
            "\n",
            "[173/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 121 | Characters: 824\n",
            "  ‚úì Found relevant entry: GS3 - Infrastructure: Energy, Ports, Roads, Airports, Ra...\n",
            "    Preview: . Trump and his molecule use. Second, uneven power quality and renewables, but for megawatt-hours ac...\n",
            "\n",
            "[174/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 152 | Characters: 963\n",
            "  ‚úì Found relevant entry: GS3 - Indian Economy - Effects of Liberalization on the ...\n",
            "    Preview: . tors such as textiles, apparel, footwear, leather industrial decade. In steel, India already The n...\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - Developments and their Ap...\n",
            "    Preview: . tors such as textiles, apparel, footwear, leather industrial decade. In steel, India already The n...\n",
            "\n",
            "[175/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 133 | Characters: 851\n",
            "\n",
            "[176/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 159 | Characters: 960\n",
            "\n",
            "[177/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 118 | Characters: 761\n",
            "\n",
            "[178/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 154 | Characters: 973\n",
            "\n",
            "[179/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 165 | Characters: 989\n",
            "\n",
            "[180/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 148 | Characters: 931\n",
            "\n",
            "[181/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 135 | Characters: 838\n",
            "\n",
            "[182/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 159 | Characters: 997\n",
            "\n",
            "[183/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 144 | Characters: 868\n",
            "\n",
            "[184/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 144 | Characters: 959\n",
            "\n",
            "[185/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 168 | Characters: 996\n",
            "\n",
            "[186/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 153 | Characters: 949\n",
            "  ‚úì Found relevant entry: GS2 - Bilateral, regional and global groupings and agree...\n",
            "    Preview: . caveats appear to be a Coimbatore administration. commercial windfall. Sport and politics do mix, ...\n",
            "\n",
            "[187/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 151 | Characters: 937\n",
            "  ‚úì Found relevant entry: GS2 - Government policies and interventions for developm...\n",
            "    Preview: . CM A ND-NDE YK THE HINDU Wednesday, February 4, 2026 Delhi 9 Opinion There is no case for scrappin...\n",
            "\n",
            "[188/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 129 | Characters: 851\n",
            "\n",
            "[189/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 160 | Characters: 988\n",
            "  ‚úì Found relevant entry: GS2 - Government policies and interventions for developm...\n",
            "    Preview: . the BJP ‚Äî and continues to as roads, school buildings, and Student of Jindal The MPLAD Scheme enab...\n",
            "\n",
            "[190/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 135 | Characters: 855\n",
            "  ‚úì Found relevant entry: GS2 - Parliamentary Committees and Funds...\n",
            "    Preview: . Despite the rational- las, a land-holding community AIADMK, was a devoted fol- Party (BJP) alleged...\n",
            "\n",
            "[191/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 90 | Characters: 570\n",
            "\n",
            "[192/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 139 | Characters: 873\n",
            "\n",
            "[193/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 158 | Characters: 968\n",
            "\n",
            "[194/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 157 | Characters: 980\n",
            "\n",
            "[195/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 167 | Characters: 991\n",
            "\n",
            "[196/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 155 | Characters: 939\n",
            "\n",
            "[197/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 161 | Characters: 979\n",
            "\n",
            "[198/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 132 | Characters: 791\n",
            "\n",
            "[199/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 135 | Characters: 834\n",
            "  ‚úì Found relevant entry: GS2 - Devolution of powers and finances up to local leve...\n",
            "    Preview: . The Dravidian movement of Hinduism rested on the var- cultural legitimacy. Has the 16th Finance Co...\n",
            "\n",
            "[200/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 112 | Characters: 676\n",
            "  ‚úì Found relevant entry: GS3 - Finance Commission and Centre-State financial rela...\n",
            "    Preview: . K.V. Raghunatha Reddy, told the Lok Sabha he 16th Finance Commis- tion had expanded to 2.2% of GDP...\n",
            "\n",
            "[201/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 157 | Characters: 945\n",
            "  ‚úì Found relevant entry: GS2 - Federalism: Centre-State Relations...\n",
            "    Preview: . By seen in Charts 2A and 2B which is ‚Äúundesirable‚Äù, warning that if Mr. Reddy, who was replying to...\n",
            "\n",
            "[202/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 158 | Characters: 971\n",
            "  ‚úì Found relevant entry: GS2 - Devolution of Powers and Finances up to Local Leve...\n",
            "    Preview: . to the structural issues. The 16th FY15 to ‚Çπ3,52,650 crore in FY22 nal security and defence enviro...\n",
            "  ‚úì Found relevant entry: GS3 - Government Budgeting...\n",
            "    Preview: . to the structural issues. The 16th FY15 to ‚Çπ3,52,650 crore in FY22 nal security and defence enviro...\n",
            "\n",
            "[203/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 155 | Characters: 994\n",
            "  ‚úì Found relevant entry: GS2 - Federalism: Devolution of powers and finances up t...\n",
            "    Preview: . volume is dictated by the Centre‚Äôs crore in FY26. nancial support. Also, it maintains During the d...\n",
            "\n",
            "[204/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 137 | Characters: 798\n",
            "  ‚úì Found relevant entry: GS2 - Centre-State Relations, Fiscal Federalism...\n",
            "    Preview: . This Data show the way the present 90% for the sixth consecutive year ment between the Centre and ...\n",
            "\n",
            "[205/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 101 | Characters: 653\n",
            "  ‚úì Found relevant entry: GS2 - Devolution of powers and finances up to local leve...\n",
            "    Preview: . agree with Mr. Dinen Bhattacharya that payment collected as taxes and duties that er the vertical ...\n",
            "\n",
            "[206/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 165 | Characters: 962\n",
            "  ‚úì Found relevant entry: GS2 - Devolution of powers and finances up to local leve...\n",
            "    Preview: . Constitution have ever envisioned these taxes. In 2021-22, for every As many as 18 States ‚Äî includ...\n",
            "\n",
            "[207/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 103 | Characters: 613\n",
            "  ‚úì Found relevant entry: GS3 - Government Budgeting...\n",
            "    Preview: . The GST compen- 48%. In stark contrast, the Centre that the Centre demonstrates eÔ¨É- advanced stage...\n",
            "\n",
            "[208/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 103 | Characters: 665\n",
            "\n",
            "[209/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 89 | Characters: 538\n",
            "\n",
            "[210/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 136 | Characters: 852\n",
            "\n",
            "[211/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 85 | Characters: 531\n",
            "\n",
            "[212/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 131 | Characters: 878\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - developments and their ap...\n",
            "    Preview: . PTI to 2024, which saw 94 million tourists. AP years. This was given in a written reply. PTI COMPI...\n",
            "\n",
            "[213/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 146 | Characters: 902\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - developments and their ap...\n",
            "    Preview: . consolidation. Since 2012-2013, the national space budget has grown by 182%. While this sounds mas...\n",
            "\n",
            "[214/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 129 | Characters: 857\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - developments and their ap...\n",
            "    Preview: . ‚ÄòMade in India‚Äô space hardware The 2026-2027 budget estimate is now more expensive. 5.3% higher th...\n",
            "\n",
            "[215/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 110 | Characters: 777\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - Developments and their ap...\n",
            "    Preview: . The budget numbers suggest that the state-led programme is stabilising, but by focusing almost exc...\n",
            "\n",
            "[216/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 101 | Characters: 663\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - developments and their ap...\n",
            "    Preview: . competitors in the U.S. (SpaceX, Blue burn rates, long gestation timelines and Leading up to the B...\n",
            "\n",
            "[217/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 147 | Characters: 902\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - Developments and their ap...\n",
            "    Preview: . As signiÔ¨Åcant taxes on high-tech imports and highlighted a lack of relief to plug the gap space se...\n",
            "\n",
            "[218/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 117 | Characters: 815\n",
            "  ‚úì Found relevant entry: GS3 - Indian Economy - Government Budgeting...\n",
            "    Preview: . After SEBI approved success seen in the mobile manufacturing more expensive than components from R...\n",
            "\n",
            "[219/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 123 | Characters: 754\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - Developments and their ap...\n",
            "    Preview: . ‚ÄúIt seems like provides) and Ô¨Åscal or structural support, is silent on these fronts. There is no P...\n",
            "\n",
            "[220/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 120 | Characters: 791\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - Developments and their ap...\n",
            "    Preview: . In engagement of startups.‚Äù small, relative to the industry‚Äôs needs, as supervisor and promoter of...\n",
            "\n",
            "[221/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 153 | Characters: 920\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - developments and their ap...\n",
            "    Preview: . This in In eÔ¨Äect, the government has opened than evolving into the sort of facilitator stations, l...\n",
            "\n",
            "[222/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 131 | Characters: 867\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - Developments and their ap...\n",
            "    Preview: . missions, but has ignored the Ô¨Åscal levers to support the industry,‚Äù Narayan Prasad, The global sp...\n",
            "\n",
            "[223/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 135 | Characters: 889\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - Developments and their ap...\n",
            "    Preview: . been] to create demand for high tech has resolved to reach 10% by 2030. commercial scale-up,‚Äù Delo...\n",
            "\n",
            "[224/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 139 | Characters: 940\n",
            "  ‚úì Found relevant entry: GS3 - Security challenges and their management in border...\n",
            "    Preview: . PTI English S. Upendran Why the government has increased What is the meaning of ‚Äúhumdinger‚Äù? (Usha...\n",
            "\n",
            "[225/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 140 | Characters: 834\n",
            "\n",
            "[226/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 166 | Characters: 969\n",
            "  ‚úì Found relevant entry: GS3 - Security challenges and their management in border...\n",
            "    Preview: . The FY2027 defence budget, by past obligations, which could include, ‚Äúon cloud nine‚Äù? (Surabhi Nag...\n",
            "\n",
            "[227/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 166 | Characters: 977\n",
            "  ‚úì Found relevant entry: GS3 - Government Budgeting...\n",
            "    Preview: . The total or Project 75I diesel-electric submarines, cloud nine for days. This expression is Minis...\n",
            "\n",
            "[228/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 121 | Characters: 688\n",
            "  ‚úì Found relevant entry: GS3 - Government Budgeting...\n",
            "    Preview: . FY26, it marks a signiÔ¨Åcant stabilisation budget has contracted to 21.8% in FY27, You might feel, ...\n",
            "\n",
            "[229/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 112 | Characters: 710\n",
            "  ‚úì Found relevant entry: GS3 - Government Budgeting...\n",
            "    Preview: . insulate national security imperatives high, its share of the pie is shrinking, When he was in thi...\n",
            "\n",
            "[230/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 118 | Characters: 797\n",
            "  ‚úì Found relevant entry: GS3 - Indigenization of technology and developing new te...\n",
            "    Preview: . The government has reserved Kodambakkam, Chennai) purchases of big-ticket items such as nearly 75%...\n",
            "\n",
            "[231/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 147 | Characters: 844\n",
            "  ‚úì Found relevant entry: GS3 - Defence and Security...\n",
            "    Preview: . Her parents refused to In the FY27 BE, the share of capital outlay than the RE, and the RE is near...\n",
            "\n",
            "[232/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 163 | Characters: 981\n",
            "  ‚úì Found relevant entry: GS3 - Government Budgeting...\n",
            "    Preview: . We often hear people say ‚ÄúWe the 24.5% Ô¨Ågure for FY20 (Actuals). In acknowledge three main aspects...\n",
            "\n",
            "[233/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 152 | Characters: 945\n",
            "  ‚úì Found relevant entry: GS3 - Security challenges and their management in border...\n",
            "    Preview: . ‚Çπ1,80,000 crore for capital expenses. A the Ô¨Ånancial footprint of that conÔ¨Çict is also signal that...\n",
            "\n",
            "[234/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 175 | Characters: 999\n",
            "\n",
            "[235/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 138 | Characters: 843\n",
            "\n",
            "[236/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 148 | Characters: 905\n",
            "  ‚úì Found relevant entry: GS2 - Separation of powers between various organs disput...\n",
            "    Preview: . Ans: TikTok letters@thehindu.co.in Who was the Ô¨Årst male player to complete a golden Name this pla...\n",
            "  ‚úì Found relevant entry: GS3 - Effects of liberalization on the economy, changes ...\n",
            "    Preview: . Ans: TikTok letters@thehindu.co.in Who was the Ô¨Årst male player to complete a golden Name this pla...\n",
            "\n",
            "[237/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 165 | Characters: 988\n",
            "  ‚úì Found relevant entry: GS2 - Federalism, State Legislature...\n",
            "    Preview: . This is a deal that will protect After weeks of insisting the interests of every Indian and provid...\n",
            "  ‚úì Found relevant entry: GS3 - Indian Economy, Trade Agreements...\n",
            "    Preview: . This is a deal that will protect After weeks of insisting the interests of every Indian and provid...\n",
            "\n",
            "[238/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 153 | Characters: 938\n",
            "  ‚úì Found relevant entry: GS2 - Federalism, Governor's Role, Article 174...\n",
            "    Preview: . It now admits memorandum to Governor C.V. icals, rubber goods, machinery, and aircraft challenging...\n",
            "\n",
            "[239/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 148 | Characters: 862\n",
            "  ‚úì Found relevant entry: GS2 - Separation of powers between various organs, Dispu...\n",
            "    Preview: . The Congress president applicable. takes and issuing notices to issuing notices to harass set by t...\n",
            "\n",
            "[240/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 163 | Characters: 997\n",
            "  ‚úì Found relevant entry: GS2 - State Legislature, Governor's Role, Article 174...\n",
            "    Preview: . Trump also Manipur Legislative As- and referred it to the Chief deemed to be dissolved (1)‚Äù and fu...\n",
            "\n",
            "[241/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 76 | Characters: 442\n",
            "\n",
            "[242/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 98 | Characters: 885\n",
            "  ‚úì Found relevant entry: GS2 - Separation of Powers, Federalism, Article 174...\n",
            "    Preview: . Bench. constitutional status of Ma- member House was held ‚Äúwould tantamount to the during SIR.‚Äù Th...\n",
            "\n",
            "[243/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 135 | Characters: 816\n",
            "\n",
            "[244/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 150 | Characters: 888\n",
            "  ‚úì Found relevant entry: GS2 - Data Protection and Privacy...\n",
            "    Preview: . the ongoing ethnic that day, the Governor de- ble in the absence of basic (AEROs), and booth-level...\n",
            "\n",
            "[245/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 150 | Characters: 873\n",
            "  ‚úì Found relevant entry: GS2 - Judiciary - Structure, organization and functionin...\n",
            "    Preview: . age it for online advertis- Digital Services Act. ‚ÄúThe the community, he would not join the govern...\n",
            "\n",
            "[246/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 132 | Characters: 852\n",
            "  ‚úì Found relevant entry: GS2 - Right to Privacy, Data Protection...\n",
            "    Preview: . Is it an nipur, said, ‚ÄúA lot of back-channel eÔ¨Äorts went in Growing cases of harass- breach the ri...\n",
            "\n",
            "[247/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 143 | Characters: 997\n",
            "  ‚úì Found relevant entry: GS2 - Data Protection and Privacy...\n",
            "    Preview: . Face-oÔ¨Ä in LS over lytheonrulingTuesday,NationalwithConfe-both personalA three-judgedata. Bench th...\n",
            "\n",
            "[248/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 168 | Characters: 996\n",
            "  ‚úì Found relevant entry: GS2 - Government policies and interventions for developm...\n",
            "    Preview: . private data to a ‚Äúdecent stressed that messages on the law on the sharing of products‚Äù. ‚Çπ213.14-c...\n",
            "\n",
            "[249/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 166 | Characters: 962\n",
            "\n",
            "[250/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 157 | Characters: 938\n",
            "\n",
            "[251/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 115 | Characters: 741\n",
            "  ‚úì Found relevant entry: GS2 - National Security Act, 1980...\n",
            "    Preview: . Tenneti to adjourn the House until 3 p.m. ed an atmosphere of fear and insecurity among fa- Shiv S...\n",
            "\n",
            "[252/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 85 | Characters: 491\n",
            "\n",
            "[253/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 162 | Characters: 991\n",
            "\n",
            "[254/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 153 | Characters: 924\n",
            "\n",
            "[255/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 171 | Characters: 974\n",
            "\n",
            "[256/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 169 | Characters: 972\n",
            "\n",
            "[257/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 123 | Characters: 724\n",
            "\n",
            "[258/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 162 | Characters: 952\n",
            "  ‚úì Found relevant entry: GS2 - Bilateral, regional and global groupings and agree...\n",
            "    Preview: . deal a ‚Äòbig decision‚Äô that will NDA ally TDP seeks clarity on India-U.S. trade deal; beneÔ¨Åt India,...\n",
            "\n",
            "[259/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 143 | Characters: 866\n",
            "  ‚úì Found relevant entry: GS2 - Bilateral, regional and global groupings and agree...\n",
            "    Preview: . ‚ÄúI therefore cratic Alliance‚Äôs country,‚Äù he said. municate the details of the appeal to the govern...\n",
            "\n",
            "[260/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 156 | Characters: 913\n",
            "  ‚úì Found relevant entry: GS3 - International Trade...\n",
            "    Preview: . The Telugu reciprocal tariÔ¨Ä from 25% After Zero Hour, the ly, the Prime Minister said work. Desam ...\n",
            "\n",
            "[261/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 138 | Characters: 776\n",
            "\n",
            "[262/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 144 | Characters: 873\n",
            "\n",
            "[263/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 156 | Characters: 947\n",
            "  ‚úì Found relevant entry: GS2 - International Relations...\n",
            "    Preview: . Opposition MPs, bin, who was present. agreement as a ‚Äúbig deci- 2047, when India com- that these t...\n",
            "\n",
            "[264/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 155 | Characters: 932\n",
            "  ‚úì Found relevant entry: GS2 - India and its neighborhood- relations, Bilateral, ...\n",
            "    Preview: . Yadav further point- in creating politics out of situation was being not- Sitharaman for presentin...\n",
            "\n",
            "[265/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 153 | Characters: 863\n",
            "  ‚úì Found relevant entry: GS2 - Bilateral, regional and global groupings and agree...\n",
            "    Preview: . Trump‚Äôs reference to a not responded to requests Press Trust of India A. M. Jigeesh cha (SKM), an ...\n",
            "\n",
            "[266/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 150 | Characters: 861\n",
            "  ‚úì Found relevant entry: GS2 - Bilateral, regional and global groupings and agree...\n",
            "    Preview: . goods Russian oil imports, is a U.S. Free Trade Agreement icted by Mr. Trump‚Äôs state- purchases, K...\n",
            "\n",
            "[267/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 177 | Characters: 964\n",
            "  ‚úì Found relevant entry: GS2 - Bilateral, regional and global groupings and agree...\n",
            "    Preview: . As a result of the ry which India has been comment on whether any Will India have to give nald Tru...\n",
            "\n",
            "[268/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 161 | Characters: 948\n",
            "  ‚úì Found relevant entry: GS2 - India and its neighborhood- relations...\n",
            "    Preview: . has only 18.8 lakh ter S. Jaishankar‚Äôs visit to far been released by either new U.S.-India deal wi...\n",
            "\n",
            "[269/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 154 | Characters: 899\n",
            "  ‚úì Found relevant entry: GS2 - India and its neighborhood- relations...\n",
            "    Preview: . The U.S. has also on this matter yet,‚Äù Mr. sociation of India (SEAI) agricultural census of nald T...\n",
            "\n",
            "[270/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 149 | Characters: 819\n",
            "\n",
            "[271/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 135 | Characters: 826\n",
            "\n",
            "[272/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 173 | Characters: 985\n",
            "  ‚úì Found relevant entry: GS2 - Parliament and State Legislatures ‚Äì structure, fun...\n",
            "    Preview: . trade deal in Rajya Sabha attend court Gyanesh Kumar: Mamata The Hindu Bureau dia (Marxist) leader...\n",
            "\n",
            "[273/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 159 | Characters: 944\n",
            "  ‚úì Found relevant entry: GS2 - Election Commission of India, Constitutional Bodie...\n",
            "    Preview: . dian Union Muslim League Surya Kant in a case chal- amenable to an impeach- the process of impeach...\n",
            "\n",
            "[274/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 160 | Characters: 925\n",
            "\n",
            "[275/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 166 | Characters: 958\n",
            "\n",
            "[276/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 179 | Characters: 992\n",
            "\n",
            "[277/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 151 | Characters: 901\n",
            "  ‚úì Found relevant entry: GS2 - Judiciary - Structure, functioning, and reforms...\n",
            "    Preview: . Communist Party of In- only 18%,‚Äù he said. CM A ND-NDE YK THE HINDU 14 Wednesday, February 4, 2026...\n",
            "  ‚úì Found relevant entry: GS2 - International Relations - Global groupings and agr...\n",
            "    Preview: . Communist Party of In- only 18%,‚Äù he said. CM A ND-NDE YK THE HINDU 14 Wednesday, February 4, 2026...\n",
            "\n",
            "[278/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 136 | Characters: 821\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - Developments and their ap...\n",
            "    Preview: . ing 5.4 million children un- In 2024, international The Defence Research and Development T a singl...\n",
            "\n",
            "[279/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 152 | Characters: 965\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - Developments and their ap...\n",
            "    Preview: . published by the Square orders cet Global Health on their ODA contributions According to the Minis...\n",
            "  ‚úì Found relevant entry: GS2 - Judiciary - Structure, organization and functionin...\n",
            "    Preview: . published by the Square orders cet Global Health on their ODA contributions According to the Minis...\n",
            "\n",
            "[280/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 112 | Characters: 679\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - Developments and their ap...\n",
            "    Preview: . Defence ers who had been on death Court in Manoj vs State of with 21 of the countries in the world...\n",
            "\n",
            "[281/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 97 | Characters: 590\n",
            "  ‚úì Found relevant entry: GS2 - Judiciary and Justice Delivery System...\n",
            "    Preview: . The report, which exa- Ô¨Årmed. The High Courts ac- ‚ÄúWhat is starkly clear from duct reports, and mi...\n",
            "  ‚úì Found relevant entry: GS3 - International Organizations and Global Groupings...\n",
            "    Preview: . The report, which exa- Ô¨Årmed. The High Courts ac- ‚ÄúWhat is starkly clear from duct reports, and mi...\n",
            "\n",
            "[282/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 135 | Characters: 841\n",
            "  ‚úì Found relevant entry: GS2 - Judicial reforms, Death penalty...\n",
            "    Preview: . only leading to wrongful requirement in Vasanta globally. study, ICREA Research e2145468 Security ...\n",
            "\n",
            "[283/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 162 | Characters: 978\n",
            "\n",
            "[284/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 175 | Characters: 992\n",
            "  ‚úì Found relevant entry: GS2 - Judicial System and Reforms...\n",
            "    Preview: . port said. not a single sentence has said. ningful defence represen- ria and nutritional deÔ¨Å- now ...\n",
            "\n",
            "[285/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 159 | Characters: 923\n",
            "  ‚úì Found relevant entry: GS2 - Welfare schemes for vulnerable sections of the pop...\n",
            "    Preview: . A Ô¨ÅreÔ¨Åght is on. The operation ed down by the High cided by the Supreme December 31, 2025. The av-...\n",
            "\n",
            "[286/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 166 | Characters: 979\n",
            "\n",
            "[287/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 154 | Characters: 939\n",
            "\n",
            "[288/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 124 | Characters: 754\n",
            "  ‚úì Found relevant entry: GS2 - Government policies and interventions for developm...\n",
            "    Preview: . lated the matter to Boeing the General category. validated. deaths due to hazardous 1,286 workers ...\n",
            "\n",
            "[289/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 98 | Characters: 610\n",
            "  ‚úì Found relevant entry: GS2 - Government schemes for vulnerable sections...\n",
            "    Preview: . The en- total of 1.52 lakh waste- scheme, waste-pickers sewer and septic tank Dreamliner aircraft ...\n",
            "\n",
            "[290/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 114 | Characters: 701\n",
            "\n",
            "[291/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 139 | Characters: 889\n",
            "\n",
            "[292/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 148 | Characters: 874\n",
            "\n",
            "[293/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 151 | Characters: 925\n",
            "\n",
            "[294/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 141 | Characters: 782\n",
            "\n",
            "[295/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 133 | Characters: 971\n",
            "\n",
            "[296/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 237 | Characters: 833\n",
            "\n",
            "[297/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 286 | Characters: 999\n",
            "  ‚úì Found relevant entry: GS2 - India and its neighborhood- relations...\n",
            "    Preview: . . Auto 9595.50. 99.00 . . . . . . . . . . . .. . . . . . . . . . . . . . . Bajaj Finserv . 2012.70...\n",
            "\n",
            "[298/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 273 | Characters: 997\n",
            "  ‚úì Found relevant entry: GS2 - India and its neighborhood- relations...\n",
            "    Preview: . . . . . . . . . . . . . . . . .. . . . . . . . . 429.40. . . . . . . . . . . . 5.90 the power sect...\n",
            "\n",
            "[299/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 244 | Characters: 999\n",
            "\n",
            "[300/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 235 | Characters: 897\n",
            "\n",
            "[301/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 300 | Characters: 980\n",
            "  ‚úì Found relevant entry: GS2 - Bilateral, regional and global groupings and agree...\n",
            "    Preview: . Servic-. . . . . . . . . . . .. . . . . . . . . 263.90. . . . . . . . . . 19.80 India and the U.S....\n",
            "\n",
            "[302/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 247 | Characters: 862\n",
            "\n",
            "[303/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 243 | Characters: 996\n",
            "\n",
            "[304/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 223 | Characters: 999\n",
            "\n",
            "[305/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 271 | Characters: 994\n",
            "\n",
            "[306/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 219 | Characters: 996\n",
            "\n",
            "[307/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 132 | Characters: 818\n",
            "\n",
            "[308/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 157 | Characters: 920\n",
            "\n",
            "[309/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 147 | Characters: 906\n",
            "  ‚úì Found relevant entry: GS3 - Make in India, Defence Technology...\n",
            "    Preview: . the global competitiveness ceutical industry‚Äôs total re- turing opportunities and come globally wi...\n",
            "\n",
            "[310/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 110 | Characters: 683\n",
            "\n",
            "[311/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 150 | Characters: 917\n",
            "\n",
            "[312/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 155 | Characters: 898\n",
            "\n",
            "[313/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 151 | Characters: 900\n",
            "\n",
            "[314/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 155 | Characters: 930\n",
            "\n",
            "[315/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 76 | Characters: 475\n",
            "\n",
            "[316/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 157 | Characters: 988\n",
            "  ‚úì Found relevant entry: GS2 - International Relations...\n",
            "    Preview: . Central Command said on Tuesday that a U.S. Navy Ô¨Åghter jet Myanmar and Russia have signed a Ô¨Åve-y...\n",
            "  ‚úì Found relevant entry: GS2 - International Relations...\n",
            "    Preview: . Central Command said on Tuesday that a U.S. Navy Ô¨Åghter jet Myanmar and Russia have signed a Ô¨Åve-y...\n",
            "\n",
            "[317/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 100 | Characters: 633\n",
            "\n",
            "[318/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 127 | Characters: 806\n",
            "  ‚úì Found relevant entry: GS2 - International Relations...\n",
            "    Preview: . response to one-year extension oÔ¨Äer; Russian drones strike Ukraine ahead of talks Iran‚Äôs President...\n",
            "\n",
            "[319/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 143 | Characters: 848\n",
            "  ‚úì Found relevant entry: GS2 - International Relations...\n",
            "    Preview: . troop mo- ‚ÄúThese negotiations the previous day. T the world was limiting the United States, bilisa...\n",
            "\n",
            "[320/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 158 | Characters: 928\n",
            "  ‚úì Found relevant entry: GS2 - International Relations: Bilateral, regional and g...\n",
            "    Preview: . in the region to respond to post. On Monday, the State Hamas war. clear treaty between Wash- Meanw...\n",
            "\n",
            "[321/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 63 | Characters: 388\n",
            "\n",
            "[322/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 175 | Characters: 976\n",
            "\n",
            "[323/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 127 | Characters: 818\n",
            "  ‚úì Found relevant entry: GS2 - India and its neighborhood- relations...\n",
            "    Preview: . kesperson Dmitry Peskov cans to this initiative‚Äù. would limit and control Dhabi. dignity, prudence...\n",
            "\n",
            "[324/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 164 | Characters: 996\n",
            "\n",
            "[325/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 135 | Characters: 870\n",
            "  ‚úì Found relevant entry: GS2 - India and its neighborhood- relations...\n",
            "    Preview: . Since 2018, major against the Pakistani mili- previous year. Pakistani state in 1948. The factions...\n",
            "\n",
            "[326/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 111 | Characters: 764\n",
            "  ‚úì Found relevant entry: GS2 - India and its neighborhood- relations...\n",
            "    Preview: . Militants have against the militants across Arabian Sea coastline, and tants. Amnesty Interna- inc...\n",
            "\n",
            "[327/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 154 | Characters: 990\n",
            "  ‚úì Found relevant entry: GS2 - India and its neighborhood- relations...\n",
            "    Preview: . is behind these attacks. I and molybdenum ‚Äî is con- and military operations The Pakistani state of...\n",
            "\n",
            "[328/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 71 | Characters: 489\n",
            "\n",
            "[329/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 140 | Characters: 902\n",
            "  ‚úì Found relevant entry: GS2 - India and its neighborhood- relations...\n",
            "    Preview: . Following the ‚ÄúInstead of parroting frivo- try of External AÔ¨Äairs. Missouri-based mining Taliban t...\n",
            "  ‚úì Found relevant entry: GS3 - Security challenges and their management in border...\n",
            "    Preview: . Following the ‚ÄúInstead of parroting frivo- try of External AÔ¨Äairs. Missouri-based mining Taliban t...\n",
            "\n",
            "[330/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 176 | Characters: 964\n",
            "\n",
            "[331/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 176 | Characters: 990\n",
            "\n",
            "[332/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 160 | Characters: 926\n",
            "\n",
            "[333/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 123 | Characters: 740\n",
            "\n",
            "[334/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 155 | Characters: 813\n",
            "\n",
            "[335/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 185 | Characters: 980\n",
            "\n",
            "[336/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 179 | Characters: 994\n",
            "\n",
            "[337/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 136 | Characters: 801\n",
            "\n",
            "[338/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 166 | Characters: 881\n",
            "\n",
            "[339/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 152 | Characters: 822\n",
            "\n",
            "[340/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 163 | Characters: 979\n",
            "\n",
            "[341/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 162 | Characters: 964\n",
            "\n",
            "[342/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 159 | Characters: 907\n",
            "\n",
            "[343/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 165 | Characters: 955\n",
            "\n",
            "[344/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 158 | Characters: 904\n",
            "\n",
            "[345/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 160 | Characters: 961\n",
            "\n",
            "[346/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 145 | Characters: 836\n",
            "\n",
            "[347/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 131 | Characters: 762\n",
            "\n",
            "[348/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 98 | Characters: 565\n",
            "\n",
            "[349/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 160 | Characters: 889\n",
            "\n",
            "[350/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 173 | Characters: 946\n",
            "\n",
            "[351/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 173 | Characters: 958\n",
            "\n",
            "[352/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 113 | Characters: 653\n",
            "\n",
            "[353/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 126 | Characters: 677\n",
            "\n",
            "[354/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 158 | Characters: 928\n",
            "\n",
            "[355/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 171 | Characters: 991\n",
            "\n",
            "[356/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 173 | Characters: 975\n",
            "\n",
            "[357/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 143 | Characters: 842\n",
            "\n",
            "[358/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 158 | Characters: 878\n",
            "\n",
            "[359/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 161 | Characters: 981\n",
            "\n",
            "[360/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 124 | Characters: 743\n",
            "\n",
            "[361/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 150 | Characters: 929\n",
            "\n",
            "[362/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 97 | Characters: 627\n",
            "\n",
            "[363/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 168 | Characters: 999\n",
            "\n",
            "[364/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 141 | Characters: 779\n",
            "\n",
            "[365/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 177 | Characters: 980\n",
            "\n",
            "[366/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 159 | Characters: 846\n",
            "\n",
            "[367/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 176 | Characters: 996\n",
            "\n",
            "[368/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 156 | Characters: 917\n",
            "\n",
            "[369/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 174 | Characters: 973\n",
            "\n",
            "[370/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 174 | Characters: 900\n",
            "\n",
            "[371/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 163 | Characters: 890\n",
            "\n",
            "[372/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 168 | Characters: 887\n",
            "\n",
            "[373/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 177 | Characters: 980\n",
            "\n",
            "[374/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 180 | Characters: 971\n",
            "\n",
            "[375/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 167 | Characters: 859\n",
            "\n",
            "[376/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 151 | Characters: 852\n",
            "\n",
            "[377/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 134 | Characters: 817\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - developments and their ap...\n",
            "    Preview: . But we were clear coming CM S ND-NDE YK THE HINDU II Wednesday, February 4, 2026 Delhi SCIENCE Ind...\n",
            "\n",
            "[378/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 108 | Characters: 685\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - developments and their ap...\n",
            "    Preview: . localities in which wastewater In their study, detailed in a paper treatment is inadequate or publ...\n",
            "\n",
            "[379/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 113 | Characters: 719\n",
            "\n",
            "[380/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 153 | Characters: 990\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - Developments and their ap...\n",
            "    Preview: . antibiotics or resistance genes are studying them at genomic, The approach is similar to a rapid p...\n",
            "\n",
            "[381/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 129 | Characters: 789\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - developments and their ap...\n",
            "    Preview: . process them to isolate the genetic population. reliably indicate resistant pathogens. material, t...\n",
            "\n",
            "[382/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 85 | Characters: 509\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - developments and their ap...\n",
            "    Preview: . If the AMR genes are present in its aÔ¨Äordability, with a unit cost of just proof of concept develo...\n",
            "\n",
            "[383/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 127 | Characters: 771\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - developments and their ap...\n",
            "    Preview: . exceptionally well understood. and thus a clear visual readout. whose cost can exceed ‚Çπ9,000. Dr. ...\n",
            "\n",
            "[384/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 127 | Characters: 818\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - developments and their ap...\n",
            "    Preview: . hours. In case new resistance genes are diÔ¨Äerentiate SARS-CoV-2 variants. pathogen,‚Äù he added. dis...\n",
            "\n",
            "[385/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 138 | Characters: 953\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - developments and their ap...\n",
            "    Preview: . As a result, minimal-resource settings,‚Äù THSTI resistance expert and retired professor at wastewat...\n",
            "\n",
            "[386/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 146 | Characters: 951\n",
            "  ‚úì Found relevant entry: GS3 - Science and Technology - developments and their ap...\n",
            "    Preview: . resistance genes, they are not feasible to Because resistance to antibiotics can be spread of resi...\n",
            "\n",
            "[387/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 68 | Characters: 848\n",
            "\n",
            "[388/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 163 | Characters: 989\n",
            "\n",
            "[389/389] Processing chunk from TH Delhi 04-02-2026 (1) (2) (1).pdf...\n",
            "  Words: 130 | Characters: 820\n",
            "  ‚úì Found relevant entry: GS3 - Disaster Management...\n",
            "    Preview: . private individuals who want to The experience usually lasts between experience spaceÔ¨Çight. 10 and...\n",
            "\n",
            "================================================================================\n",
            "‚úÖ PROCESSING COMPLETE\n",
            "================================================================================\n",
            "Total entries: 447\n",
            "‚úì Relevant: 158\n",
            "‚úó Irrelevant: 289\n",
            "Relevance rate: 35.3%\n",
            "================================================================================\n",
            "\n",
            "üìë SUMMARY BY SOURCE:\n",
            "  ‚Ä¢ Bollywood-Town-February-2026 (4).pdf: 0/82 relevant\n",
            "  ‚Ä¢ sportstar (3).pdf: 0/1 relevant\n",
            "  ‚Ä¢ TH Delhi 04-02-2026 (1) (2) (1).pdf: 158/364 relevant\n",
            "\n",
            "üìö SUMMARY BY GS PAPER:\n",
            "  ‚Ä¢ GS2: 82 entries\n",
            "  ‚Ä¢ GS3: 74 entries\n",
            "  ‚Ä¢ GS1: 2 entries\n",
            "\n",
            "üìñ TOP 10 SYLLABUS TOPICS:\n",
            "  ‚Ä¢ Science and Technology - developments and their applications...: 13\n",
            "  ‚Ä¢ Infrastructure: Energy, Ports, Roads, Airports, Railways etc...: 13\n",
            "  ‚Ä¢ India and its neighborhood- relations: 11\n",
            "  ‚Ä¢ Science and Technology - Developments and their applications...: 10\n",
            "  ‚Ä¢ Government Budgeting: 9\n",
            "  ‚Ä¢ Bilateral, regional and global groupings and agreements invo...: 8\n",
            "  ‚Ä¢ Government policies and interventions for development in var...: 6\n",
            "  ‚Ä¢ International Relations: 5\n",
            "  ‚Ä¢ Government policies and interventions for development in var...: 4\n",
            "  ‚Ä¢ Conservation, environmental pollution and degradation, envir...: 4\n",
            "\n",
            "üíæ Dataset saved: upsc_dataset_langchain_20260213_095213.csv\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a5da7a6f-8546-4f98-b5ca-c90978bebeb2\", \"upsc_dataset_langchain_20260213_095213.csv\", 605510)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UPSC Dataset Accuracy Testing with Qwen2.5-1.5B (Student Model)\n",
        "# LOCAL INFERENCE VERSION - Loads model directly in Google Colab\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "from google.colab import files\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from typing import List, Dict\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "STUDENT_MODEL = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MAX_NEW_TOKENS = 512\n",
        "TEMPERATURE = 0.7\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\" \"*20 + \"QWEN2.5-1.5B LOCAL INFERENCE SETUP\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüñ•Ô∏è  Device: {DEVICE}\")\n",
        "print(f\"üì¶ Model: {STUDENT_MODEL}\")\n",
        "\n",
        "class LocalQwenEvaluator:\n",
        "    \"\"\"Evaluator class for testing Qwen2.5-1.5B with local inference.\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = STUDENT_MODEL):\n",
        "        self.model_name = model_name\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self.device = DEVICE\n",
        "        self._debug_count = 0\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load the model and tokenizer with comprehensive verification.\"\"\"\n",
        "        print(f\"\\nüîÑ Loading {self.model_name}...\")\n",
        "        print(\"‚è≥ This may take a few minutes on first run...\")\n",
        "\n",
        "        try:\n",
        "            print(\"  üìù Loading tokenizer...\")\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                self.model_name,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            if self.tokenizer is None:\n",
        "                raise ValueError(\"‚ùå Tokenizer failed to load!\")\n",
        "\n",
        "            print(f\"  ‚úì Tokenizer loaded: {len(self.tokenizer)} tokens in vocabulary\")\n",
        "            print(f\"  ‚úì Special tokens: EOS={self.tokenizer.eos_token}, PAD={self.tokenizer.pad_token}\")\n",
        "\n",
        "            print(\"  ü§ñ Loading model...\")\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32,\n",
        "                device_map=\"auto\" if self.device == \"cuda\" else None,\n",
        "                trust_remote_code=True,\n",
        "                low_cpu_mem_usage=True\n",
        "            )\n",
        "\n",
        "            if self.model is None:\n",
        "                raise ValueError(\"‚ùå Model failed to load!\")\n",
        "\n",
        "            if self.device == \"cpu\":\n",
        "                self.model = self.model.to(self.device)\n",
        "\n",
        "            self.model.eval()\n",
        "\n",
        "            print(f\"\\n  üîç Running verification checks...\")\n",
        "\n",
        "            total_params = sum(p.numel() for p in self.model.parameters())\n",
        "            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "            print(f\"  ‚úì Total parameters: {total_params:,} ({total_params/1e9:.2f}B)\")\n",
        "            print(f\"  ‚úì Trainable parameters: {trainable_params:,}\")\n",
        "            print(f\"  ‚úì Model in eval mode: {not self.model.training}\")\n",
        "\n",
        "            first_param_device = next(self.model.parameters()).device\n",
        "            print(f\"  ‚úì Model device: {first_param_device}\")\n",
        "\n",
        "            first_param_dtype = next(self.model.parameters()).dtype\n",
        "            print(f\"  ‚úì Model dtype: {first_param_dtype}\")\n",
        "\n",
        "            if self.device == \"cuda\":\n",
        "                allocated = torch.cuda.memory_allocated() / 1024**3\n",
        "                reserved = torch.cuda.memory_reserved() / 1024**3\n",
        "                print(f\"  ‚úì GPU Memory Allocated: {allocated:.2f} GB\")\n",
        "                print(f\"  ‚úì GPU Memory Reserved: {reserved:.2f} GB\")\n",
        "\n",
        "            print(f\"\\n  üß™ Running test inference...\")\n",
        "            test_result = self._test_inference()\n",
        "\n",
        "            if test_result:\n",
        "                print(f\"  ‚úÖ Test inference SUCCESSFUL!\")\n",
        "                print(f\"  ‚úì Model is ready for evaluation\")\n",
        "            else:\n",
        "                print(f\"  ‚ö†Ô∏è  Test inference FAILED - check configuration\")\n",
        "\n",
        "            print(f\"\\n‚úÖ Model loaded and verified successfully on {self.device}!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå Error loading model: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            raise\n",
        "\n",
        "    def _test_inference(self) -> bool:\n",
        "        \"\"\"Run a simple test to verify model can generate text.\"\"\"\n",
        "        try:\n",
        "            test_messages = [\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": \"Return only the word 'SUCCESS' if you understand.\"}\n",
        "            ]\n",
        "\n",
        "            text = self.tokenizer.apply_chat_template(\n",
        "                test_messages,\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=True\n",
        "            )\n",
        "\n",
        "            model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                generated_ids = self.model.generate(\n",
        "                    **model_inputs,\n",
        "                    max_new_tokens=20,\n",
        "                    do_sample=False,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            generated_ids = [\n",
        "                output_ids[len(input_ids):]\n",
        "                for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "            ]\n",
        "\n",
        "            response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "            print(f\"  Test response: '{response[:100]}'\")\n",
        "\n",
        "            return len(response) > 0 and len(response) < 1000\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Test inference error: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return False\n",
        "\n",
        "    def check_model_health(self):\n",
        "        \"\"\"Comprehensive health check of loaded model.\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"üè• MODEL HEALTH CHECK\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        checks_passed = 0\n",
        "        total_checks = 7\n",
        "\n",
        "        if self.model is not None:\n",
        "            print(\"‚úì Model object exists\")\n",
        "            checks_passed += 1\n",
        "        else:\n",
        "            print(\"‚ùå Model object is None\")\n",
        "            return False\n",
        "\n",
        "        if self.tokenizer is not None:\n",
        "            print(\"‚úì Tokenizer object exists\")\n",
        "            checks_passed += 1\n",
        "        else:\n",
        "            print(\"‚ùå Tokenizer object is None\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            param_device = str(next(self.model.parameters()).device)\n",
        "            if self.device in param_device or (self.device == \"cuda\" and \"cuda\" in param_device):\n",
        "                print(f\"‚úì Model on correct device: {param_device}\")\n",
        "                checks_passed += 1\n",
        "            else:\n",
        "                print(f\"‚ùå Model on wrong device: {param_device} (expected {self.device})\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Cannot check device: {e}\")\n",
        "\n",
        "        if not self.model.training:\n",
        "            print(\"‚úì Model in eval mode\")\n",
        "            checks_passed += 1\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è  Model in training mode (should be eval)\")\n",
        "\n",
        "        try:\n",
        "            test_input = self.tokenizer(\"test\", return_tensors=\"pt\").to(self.device)\n",
        "            print(\"‚úì Model can accept tokenized inputs\")\n",
        "            checks_passed += 1\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Cannot tokenize inputs: {e}\")\n",
        "\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                output = self.model.generate(**test_input, max_new_tokens=5)\n",
        "            print(\"‚úì Model can generate outputs\")\n",
        "            checks_passed += 1\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Cannot generate: {e}\")\n",
        "\n",
        "        if self.device == \"cuda\":\n",
        "            try:\n",
        "                free_memory = (torch.cuda.get_device_properties(0).total_memory -\n",
        "                              torch.cuda.memory_allocated()) / 1024**3\n",
        "                if free_memory > 0.5:\n",
        "                    print(f\"‚úì Sufficient GPU memory: {free_memory:.2f} GB free\")\n",
        "                    checks_passed += 1\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è  Low GPU memory: {free_memory:.2f} GB free\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è  Cannot check GPU memory: {e}\")\n",
        "        else:\n",
        "            checks_passed += 1\n",
        "            print(\"‚úì CPU mode (memory check skipped)\")\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"üìä Health Check: {checks_passed}/{total_checks} checks passed\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "\n",
        "        return checks_passed >= 6\n",
        "\n",
        "    def call_qwen_student(self, text_chunk: str) -> Dict:\n",
        "        \"\"\"Call Qwen2.5-1.5B locally to classify UPSC relevance.\"\"\"\n",
        "\n",
        "        system_prompt = \"\"\"You are a UPSC CSE Mains examiner. Evaluate if this newspaper content is relevant for UPSC exam preparation.\n",
        "\n",
        "RELEVANT examples (mark as relevant=true):\n",
        "- Government policies and reforms\n",
        "- Court judgments on constitutional matters\n",
        "- Economic policies and fiscal measures\n",
        "- International relations and diplomacy\n",
        "- Social issues with ethical dimensions\n",
        "- Environmental policies and climate action\n",
        "- Science and technology with policy impact\n",
        "- Governance and administrative reforms\n",
        "\n",
        "IRRELEVANT examples (mark as relevant=false):\n",
        "- Pure entertainment news\n",
        "- Sports scores without policy angle\n",
        "- Celebrity gossip\n",
        "- Simple crime reports\n",
        "- Advertisements\n",
        "\n",
        "Be GENEROUS in marking content as relevant if it has ANY connection to governance, policy, society, economy, international affairs, or ethics.\n",
        "\n",
        "For RELEVANT content, identify the GS Paper:\n",
        "- GS1: History, Geography, Society, Culture\n",
        "- GS2: Governance, Constitution, Polity, Social Justice, International Relations\n",
        "- GS3: Economy, Agriculture, Science & Tech, Environment, Security\n",
        "- GS4: Ethics, Integrity, Aptitude\n",
        "\n",
        "OUTPUT FORMAT (return ONLY this JSON, nothing else):\n",
        "{\n",
        "  \"relevant\": true,\n",
        "  \"gs_paper\": \"GS2\",\n",
        "  \"syllabus_topic\": \"governance and public policy\",\n",
        "  \"confidence\": 0.85\n",
        "}\n",
        "\n",
        "OR for irrelevant:\n",
        "{\n",
        "  \"relevant\": false,\n",
        "  \"gs_paper\": \"Not Applicable\",\n",
        "  \"syllabus_topic\": \"Not Applicable\",\n",
        "  \"confidence\": 0.90\n",
        "}\"\"\"\n",
        "\n",
        "        user_message = f\"Evaluate this text for UPSC relevance:\\n\\n{text_chunk[:3500]}\"\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_message}\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            text = self.tokenizer.apply_chat_template(\n",
        "                messages,\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=True\n",
        "            )\n",
        "\n",
        "            model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                generated_ids = self.model.generate(\n",
        "                    **model_inputs,\n",
        "                    max_new_tokens=MAX_NEW_TOKENS,\n",
        "                    temperature=TEMPERATURE,\n",
        "                    do_sample=True,\n",
        "                    top_p=0.9,\n",
        "                    repetition_penalty=1.1,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            generated_ids = [\n",
        "                output_ids[len(input_ids):]\n",
        "                for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "            ]\n",
        "\n",
        "            response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "            # DEBUG: Print first 3 responses\n",
        "            if self._debug_count < 3:\n",
        "                print(f\"\\nüîç DEBUG Response #{self._debug_count + 1}:\")\n",
        "                print(f\"Raw output: {response[:300]}\")\n",
        "                self._debug_count += 1\n",
        "\n",
        "            result = self._extract_json(response)\n",
        "\n",
        "            if result:\n",
        "                return self._validate_result(result)\n",
        "            else:\n",
        "                if self._debug_count <= 3:\n",
        "                    print(f\"  ‚ö†Ô∏è  JSON parsing failed. Raw: {response[:200]}\")\n",
        "                return self._fallback_classification(response, text_chunk)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ö†Ô∏è  Generation error: {str(e)[:100]}\")\n",
        "            return self._default_response()\n",
        "\n",
        "    def _extract_json(self, response: str) -> Dict:\n",
        "        \"\"\"Extract JSON from response with multiple fallback methods.\"\"\"\n",
        "        # Method 1: Find JSON between curly braces (nested-aware)\n",
        "        brace_count = 0\n",
        "        start_idx = -1\n",
        "        for i, char in enumerate(response):\n",
        "            if char == '{':\n",
        "                if start_idx == -1:\n",
        "                    start_idx = i\n",
        "                brace_count += 1\n",
        "            elif char == '}':\n",
        "                brace_count -= 1\n",
        "                if brace_count == 0 and start_idx != -1:\n",
        "                    try:\n",
        "                        json_str = response[start_idx:i+1]\n",
        "                        return json.loads(json_str)\n",
        "                    except:\n",
        "                        start_idx = -1\n",
        "                        continue\n",
        "\n",
        "        # Method 2: Remove markdown code blocks\n",
        "        cleaned = re.sub(r'```json\\s*|\\s*```', '', response)\n",
        "        json_match = re.search(r'\\{[^{}]*\\}', cleaned)\n",
        "        if json_match:\n",
        "            try:\n",
        "                return json.loads(json_match.group())\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Method 3: Simple regex\n",
        "        json_match = re.search(r'\\{[^{}]*\\}', response)\n",
        "        if json_match:\n",
        "            try:\n",
        "                return json.loads(json_match.group())\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Method 4: Try entire response\n",
        "        try:\n",
        "            return json.loads(response.strip())\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _fallback_classification(self, response: str, text_chunk: str) -> Dict:\n",
        "        \"\"\"Try to extract classification from non-JSON response.\"\"\"\n",
        "        response_lower = response.lower()\n",
        "\n",
        "        relevant_keywords = ['relevant', 'upsc', 'gs1', 'gs2', 'gs3', 'gs4', 'policy', 'governance',\n",
        "                            'true', 'yes', 'applicable']\n",
        "        irrelevant_keywords = ['irrelevant', 'not applicable', 'entertainment', 'sports',\n",
        "                              'false', 'no', 'celebrity']\n",
        "\n",
        "        relevant_score = sum(1 for kw in relevant_keywords if kw in response_lower)\n",
        "        irrelevant_score = sum(1 for kw in irrelevant_keywords if kw in response_lower)\n",
        "\n",
        "        # Extract GS paper if mentioned\n",
        "        gs_paper = \"Not Applicable\"\n",
        "        for paper in ['GS1', 'GS2', 'GS3', 'GS4']:\n",
        "            if paper.lower() in response_lower or paper in response:\n",
        "                gs_paper = paper\n",
        "                break\n",
        "\n",
        "        # Make a guess based on keywords\n",
        "        is_relevant = relevant_score > irrelevant_score or gs_paper != \"Not Applicable\"\n",
        "\n",
        "        # If still ambiguous, check the text content itself\n",
        "        if relevant_score == irrelevant_score:\n",
        "            text_lower = text_chunk.lower()\n",
        "            policy_keywords = ['government', 'policy', 'law', 'court', 'minister', 'parliament',\n",
        "                             'bill', 'act', 'scheme', 'reform', 'supreme court', 'high court']\n",
        "            if any(kw in text_lower for kw in policy_keywords):\n",
        "                is_relevant = True\n",
        "\n",
        "        return {\n",
        "            \"relevant\": is_relevant,\n",
        "            \"gs_paper\": gs_paper if is_relevant else \"Not Applicable\",\n",
        "            \"syllabus_topic\": \"Extracted from response\",\n",
        "            \"confidence\": 0.5\n",
        "        }\n",
        "\n",
        "    def _validate_result(self, result: Dict) -> Dict:\n",
        "        \"\"\"Validate and normalize the result dictionary.\"\"\"\n",
        "        validated = {\n",
        "            \"relevant\": bool(result.get(\"relevant\", False)),\n",
        "            \"gs_paper\": str(result.get(\"gs_paper\", \"Not Applicable\")),\n",
        "            \"syllabus_topic\": str(result.get(\"syllabus_topic\", \"Not Applicable\")),\n",
        "            \"confidence\": float(result.get(\"confidence\", 0.5))\n",
        "        }\n",
        "\n",
        "        if validated[\"relevant\"]:\n",
        "            if validated[\"gs_paper\"] not in [\"GS1\", \"GS2\", \"GS3\", \"GS4\"]:\n",
        "                gs_match = re.search(r'GS[1-4]', validated[\"gs_paper\"].upper())\n",
        "                if gs_match:\n",
        "                    validated[\"gs_paper\"] = gs_match.group()\n",
        "                else:\n",
        "                    # Default to GS2 (most common) with reduced confidence\n",
        "                    validated[\"gs_paper\"] = \"GS2\"\n",
        "                    validated[\"confidence\"] = max(0.3, validated[\"confidence\"] - 0.2)\n",
        "        else:\n",
        "            validated[\"gs_paper\"] = \"Not Applicable\"\n",
        "            validated[\"syllabus_topic\"] = \"Not Applicable\"\n",
        "\n",
        "        validated[\"confidence\"] = max(0.0, min(1.0, validated[\"confidence\"]))\n",
        "\n",
        "        return validated\n",
        "\n",
        "    def _default_response(self) -> Dict:\n",
        "        \"\"\"Return default response on error.\"\"\"\n",
        "        return {\n",
        "            \"relevant\": False,\n",
        "            \"gs_paper\": \"Not Applicable\",\n",
        "            \"syllabus_topic\": \"Not Applicable\",\n",
        "            \"confidence\": 0.0\n",
        "        }\n",
        "\n",
        "def calculate_metrics(y_true: List, y_pred: List, label_name: str = \"Relevance\") -> Dict:\n",
        "    \"\"\"Calculate comprehensive evaluation metrics.\"\"\"\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average='binary', zero_division=0\n",
        "    )\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"confusion_matrix\": cm,\n",
        "        \"support\": support\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üìä {label_name} Metrics\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall:    {recall:.4f}\")\n",
        "    print(f\"F1-Score:  {f1:.4f}\")\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(f\"                 Predicted\")\n",
        "    print(f\"               Neg    Pos\")\n",
        "    print(f\"Actual Neg    {cm[0][0]:4d}   {cm[0][1]:4d}\")\n",
        "    print(f\"       Pos    {cm[1][0]:4d}   {cm[1][1]:4d}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def plot_confusion_matrix(cm, title, filename):\n",
        "    \"\"\"Plot and save confusion matrix.\"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Negative', 'Positive'],\n",
        "                yticklabels=['Negative', 'Positive'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"‚úì Saved confusion matrix: {filename}\")\n",
        "\n",
        "def plot_gs_paper_accuracy(df_results, filename):\n",
        "    \"\"\"Plot accuracy by GS Paper.\"\"\"\n",
        "    gs_papers = ['GS1', 'GS2', 'GS3', 'GS4']\n",
        "    accuracies = []\n",
        "    counts = []\n",
        "\n",
        "    for paper in gs_papers:\n",
        "        paper_df = df_results[df_results['Ground_Truth_GS_Paper'] == paper]\n",
        "        if len(paper_df) > 0:\n",
        "            correct = (paper_df['Ground_Truth_GS_Paper'] == paper_df['Predicted_GS_Paper']).sum()\n",
        "            accuracy = correct / len(paper_df)\n",
        "            accuracies.append(accuracy * 100)\n",
        "            counts.append(len(paper_df))\n",
        "        else:\n",
        "            accuracies.append(0)\n",
        "            counts.append(0)\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    x = np.arange(len(gs_papers))\n",
        "    width = 0.35\n",
        "\n",
        "    ax1.bar(x - width/2, accuracies, width, label='Accuracy %', color='steelblue')\n",
        "    ax1.set_ylabel('Accuracy (%)', color='steelblue')\n",
        "    ax1.set_xlabel('GS Paper')\n",
        "    ax1.set_title('Qwen2.5-1.5B: Accuracy by GS Paper')\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(gs_papers)\n",
        "    ax1.legend(loc='upper left')\n",
        "    ax1.set_ylim([0, 105])\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.bar(x + width/2, counts, width, label='Sample Count', color='coral', alpha=0.7)\n",
        "    ax2.set_ylabel('Sample Count', color='coral')\n",
        "    ax2.legend(loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"‚úì Saved GS Paper accuracy plot: {filename}\")\n",
        "\n",
        "def plot_comparison_with_teacher(student_metrics, teacher_metrics_file=None):\n",
        "    \"\"\"Create comparison plots between student and teacher models.\"\"\"\n",
        "\n",
        "    if teacher_metrics_file:\n",
        "        try:\n",
        "            with open(teacher_metrics_file, 'r') as f:\n",
        "                teacher_metrics = json.load(f)\n",
        "        except:\n",
        "            print(\"‚ö†Ô∏è  Could not load teacher metrics for comparison\")\n",
        "            return\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  No teacher metrics file provided - skipping comparison\")\n",
        "        return\n",
        "\n",
        "    metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "    teacher_values = [\n",
        "        teacher_metrics['relevance_accuracy'],\n",
        "        teacher_metrics['relevance_precision'],\n",
        "        teacher_metrics['relevance_recall'],\n",
        "        teacher_metrics['relevance_f1']\n",
        "    ]\n",
        "    student_values = [\n",
        "        student_metrics['relevance_accuracy'],\n",
        "        student_metrics['relevance_precision'],\n",
        "        student_metrics['relevance_recall'],\n",
        "        student_metrics['relevance_f1']\n",
        "    ]\n",
        "\n",
        "    x = np.arange(len(metrics_names))\n",
        "    width = 0.35\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    bars1 = ax.bar(x - width/2, teacher_values, width, label='Teacher (72B)', color='#2E75B6')\n",
        "    bars2 = ax.bar(x + width/2, student_values, width, label='Student (1.5B)', color='#70AD47')\n",
        "\n",
        "    ax.set_ylabel('Score')\n",
        "    ax.set_title('Teacher vs Student Model Performance Comparison')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(metrics_names)\n",
        "    ax.legend()\n",
        "    ax.set_ylim([0, 1.1])\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    for bars in [bars1, bars2]:\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.annotate(f'{height:.3f}',\n",
        "                       xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                       xytext=(0, 3),\n",
        "                       textcoords=\"offset points\",\n",
        "                       ha='center', va='bottom',\n",
        "                       fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('teacher_vs_student_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"‚úì Saved comparison plot: teacher_vs_student_comparison.png\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üìä PERFORMANCE GAP ANALYSIS\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Model Size Reduction: 72B ‚Üí 1.5B (97.9% smaller)\")\n",
        "    print(f\"\\nMetric Differences (Student - Teacher):\")\n",
        "    print(f\"  Accuracy:  {student_values[0] - teacher_values[0]:+.4f} ({(student_values[0] - teacher_values[0])*100:+.2f}%)\")\n",
        "    print(f\"  Precision: {student_values[1] - teacher_values[1]:+.4f} ({(student_values[1] - teacher_values[1])*100:+.2f}%)\")\n",
        "    print(f\"  Recall:    {student_values[2] - teacher_values[2]:+.4f} ({(student_values[2] - teacher_values[2])*100:+.2f}%)\")\n",
        "    print(f\"  F1-Score:  {student_values[3] - teacher_values[3]:+.4f} ({(student_values[3] - teacher_values[3])*100:+.2f}%)\")\n",
        "\n",
        "    if 'processing_time_seconds' in teacher_metrics and 'processing_time_seconds' in student_metrics:\n",
        "        teacher_time = teacher_metrics['processing_time_seconds'] / teacher_metrics['total_samples']\n",
        "        student_time = student_metrics['processing_time_seconds'] / student_metrics['total_samples']\n",
        "        speedup = teacher_time / student_time\n",
        "        print(f\"\\nSpeed Comparison:\")\n",
        "        print(f\"  Teacher avg time: {teacher_time:.2f}s per sample\")\n",
        "        print(f\"  Student avg time: {student_time:.2f}s per sample\")\n",
        "        print(f\"  Speedup: {speedup:.2f}x faster\")\n",
        "\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "def test_student_model(csv_file_path: str, sample_size: int = None, teacher_metrics_file: str = None):\n",
        "    \"\"\"Test Qwen2.5-1.5B student model on the UPSC dataset using local inference.\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\" \"*20 + \"QWEN2.5-1.5B STUDENT MODEL TESTING\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(\"\\nüìÇ Loading dataset...\")\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "    print(f\"‚úì Loaded {len(df)} rows from {csv_file_path}\")\n",
        "\n",
        "    if sample_size and sample_size < len(df):\n",
        "        df = df.sample(n=sample_size, random_state=42)\n",
        "        print(f\"‚úì Sampled {sample_size} rows for testing\")\n",
        "\n",
        "    print(f\"\\nü§ñ Initializing Qwen2.5-1.5B evaluator...\")\n",
        "    evaluator = LocalQwenEvaluator(model_name=STUDENT_MODEL)\n",
        "    evaluator.load_model()\n",
        "\n",
        "    if not evaluator.check_model_health():\n",
        "        print(\"\\n‚ùå Model health check FAILED! Cannot proceed with evaluation.\")\n",
        "        print(\"üí° Try restarting the runtime and loading the model again.\")\n",
        "        raise RuntimeError(\"Model health check failed\")\n",
        "\n",
        "    # Test with known relevant sample\n",
        "    print(\"\\nüß™ Testing classification with sample content...\")\n",
        "    test_text = \"\"\"The Supreme Court ruled that the Right to Privacy is a fundamental right under Article 21 of the Constitution. This landmark judgment has significant implications for data protection laws and individual liberties in India.\"\"\"\n",
        "\n",
        "    test_result = evaluator.call_qwen_student(test_text)\n",
        "    print(f\"üìã Test classification result: {test_result}\")\n",
        "    print(f\"   Expected: relevant=True, gs_paper=GS2\")\n",
        "    print(f\"   Got: relevant={test_result['relevant']}, gs_paper={test_result['gs_paper']}\")\n",
        "\n",
        "    if test_result['relevant']:\n",
        "        print(\"   ‚úÖ Model correctly identified relevant content!\")\n",
        "    else:\n",
        "        print(\"   ‚ö†Ô∏è  Model marked sample as irrelevant - may be too conservative\")\n",
        "\n",
        "    print(\"\\n‚úÖ All systems ready - proceeding with evaluation...\\n\")\n",
        "\n",
        "    predictions = []\n",
        "    ground_truth_relevance = []\n",
        "    predicted_relevance = []\n",
        "    ground_truth_gs_paper = []\n",
        "    predicted_gs_paper = []\n",
        "    confidences = []\n",
        "\n",
        "    print(f\"\\nüîÑ Starting evaluation on {len(df)} samples...\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    sample_counter = 0\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Evaluating\"):\n",
        "        sample_counter += 1\n",
        "\n",
        "        result = evaluator.call_qwen_student(row['Text Chunk'])\n",
        "\n",
        "        gt_relevant = row['Relevant to UPSC']\n",
        "        gt_gs_paper = row['GS Paper'] if gt_relevant else \"Not Applicable\"\n",
        "\n",
        "        pred_relevant = result['relevant']\n",
        "        pred_gs_paper = result['gs_paper']\n",
        "        confidence = result.get('confidence', 0.0)\n",
        "\n",
        "        predictions.append({\n",
        "            'ID': row['ID'],\n",
        "            'Source_PDF': row['Source PDF'],\n",
        "            'Ground_Truth_Relevant': gt_relevant,\n",
        "            'Predicted_Relevant': pred_relevant,\n",
        "            'Ground_Truth_GS_Paper': gt_gs_paper,\n",
        "            'Predicted_GS_Paper': pred_gs_paper,\n",
        "            'Confidence': confidence,\n",
        "            'Correct_Relevance': gt_relevant == pred_relevant,\n",
        "            'Correct_GS_Paper': gt_gs_paper == pred_gs_paper if gt_relevant and pred_relevant else False\n",
        "        })\n",
        "\n",
        "        ground_truth_relevance.append(gt_relevant)\n",
        "        predicted_relevance.append(pred_relevant)\n",
        "        ground_truth_gs_paper.append(gt_gs_paper)\n",
        "        predicted_gs_paper.append(pred_gs_paper)\n",
        "        confidences.append(confidence)\n",
        "\n",
        "        if sample_counter % 5 == 0:\n",
        "            match_relevance = \"‚úì\" if gt_relevant == pred_relevant else \"‚úó\"\n",
        "            match_paper = \"‚úì\" if gt_gs_paper == pred_gs_paper else \"‚úó\"\n",
        "            print(f\"\\n[{sample_counter}/{len(df)}] ID: {row['ID']}\")\n",
        "            print(f\"  GT: Relevant={gt_relevant}, Paper={gt_gs_paper}\")\n",
        "            print(f\"  Pred: Relevant={pred_relevant}, Paper={pred_gs_paper}\")\n",
        "            print(f\"  Match: Relevance {match_relevance} | GS Paper {match_paper} | Conf: {confidence:.3f}\")\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    df_results = pd.DataFrame(predictions)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üìà EVALUATION RESULTS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    relevance_metrics = calculate_metrics(\n",
        "        ground_truth_relevance,\n",
        "        predicted_relevance,\n",
        "        \"Relevance Classification\"\n",
        "    )\n",
        "\n",
        "    relevant_mask = [gt and pred for gt, pred in zip(ground_truth_relevance, predicted_relevance)]\n",
        "    if sum(relevant_mask) > 0:\n",
        "        gs_paper_gt_filtered = [gt for gt, mask in zip(ground_truth_gs_paper, relevant_mask) if mask]\n",
        "        gs_paper_pred_filtered = [pred for pred, mask in zip(predicted_gs_paper, relevant_mask) if mask]\n",
        "\n",
        "        gs_paper_binary_gt = [1] * len(gs_paper_gt_filtered)\n",
        "        gs_paper_binary_pred = [1 if gt == pred else 0\n",
        "                                for gt, pred in zip(gs_paper_gt_filtered, gs_paper_pred_filtered)]\n",
        "\n",
        "        gs_paper_accuracy = sum(gs_paper_binary_pred) / len(gs_paper_binary_pred) if len(gs_paper_binary_pred) > 0 else 0\n",
        "\n",
        "        print(f\"üìä GS Paper Classification (among relevant items)\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Accuracy: {gs_paper_accuracy:.4f} ({gs_paper_accuracy*100:.2f}%)\")\n",
        "        print(f\"Samples:  {len(gs_paper_binary_pred)}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "    print(f\"‚è±Ô∏è  PERFORMANCE SUMMARY\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Total samples:        {len(df)}\")\n",
        "    print(f\"Processing time:      {elapsed_time:.2f} seconds\")\n",
        "    print(f\"Avg time per sample:  {elapsed_time/len(df):.2f} seconds\")\n",
        "    print(f\"Avg confidence:       {np.mean(confidences):.3f}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    print(f\"üìö BREAKDOWN BY GS PAPER\")\n",
        "    print(f\"{'='*60}\")\n",
        "    for paper in ['GS1', 'GS2', 'GS3', 'GS4']:\n",
        "        paper_df = df_results[df_results['Ground_Truth_GS_Paper'] == paper]\n",
        "        if len(paper_df) > 0:\n",
        "            correct = (paper_df['Ground_Truth_GS_Paper'] == paper_df['Predicted_GS_Paper']).sum()\n",
        "            accuracy = correct / len(paper_df)\n",
        "            print(f\"{paper}: {correct}/{len(paper_df)} correct ({accuracy*100:.1f}%)\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    output_csv = f\"qwen1.5b_student_results_{time.strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "    df_results.to_csv(output_csv, index=False)\n",
        "    print(f\"üíæ Detailed results saved: {output_csv}\")\n",
        "\n",
        "    print(f\"\\nüìä Generating visualizations...\")\n",
        "    plot_confusion_matrix(\n",
        "        relevance_metrics['confusion_matrix'],\n",
        "        'Qwen2.5-1.5B: Relevance Classification Confusion Matrix',\n",
        "        'confusion_matrix_relevance_student.png'\n",
        "    )\n",
        "\n",
        "    plot_gs_paper_accuracy(\n",
        "        df_results,\n",
        "        'gs_paper_accuracy_student.png'\n",
        "    )\n",
        "\n",
        "    metrics_summary = {\n",
        "        'model': STUDENT_MODEL,\n",
        "        'total_samples': len(df),\n",
        "        'processing_time_seconds': elapsed_time,\n",
        "        'relevance_accuracy': float(relevance_metrics['accuracy']),\n",
        "        'relevance_precision': float(relevance_metrics['precision']),\n",
        "        'relevance_recall': float(relevance_metrics['recall']),\n",
        "        'relevance_f1': float(relevance_metrics['f1_score']),\n",
        "        'avg_confidence': float(np.mean(confidences)),\n",
        "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "        'device': DEVICE\n",
        "    }\n",
        "\n",
        "    metrics_file = f\"qwen1.5b_metrics_{time.strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    with open(metrics_file, 'w') as f:\n",
        "        json.dump(metrics_summary, f, indent=2)\n",
        "\n",
        "    print(f\"‚úì Metrics summary saved: {metrics_file}\")\n",
        "\n",
        "    if teacher_metrics_file:\n",
        "        plot_comparison_with_teacher(metrics_summary, teacher_metrics_file)\n",
        "\n",
        "    print(f\"\\nüì• Downloading results...\")\n",
        "    files.download(output_csv)\n",
        "    files.download(metrics_file)\n",
        "    files.download('confusion_matrix_relevance_student.png')\n",
        "    files.download('gs_paper_accuracy_student.png')\n",
        "    if teacher_metrics_file:\n",
        "        try:\n",
        "            files.download('teacher_vs_student_comparison.png')\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"‚úÖ TESTING COMPLETE!\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    if DEVICE == \"cuda\":\n",
        "        del evaluator.model\n",
        "        torch.cuda.empty_cache()\n",
        "        print(f\"üßπ GPU memory cleared\")\n",
        "\n",
        "    return df_results, metrics_summary\n",
        "\n",
        "# --- MAIN EXECUTION ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚öôÔ∏è  SYSTEM CHECK\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"CUDA version: {torch.version.cuda}\")\n",
        "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(\"\\nüì§ Upload your UPSC dataset CSV file (with ground truth labels)\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"\\n‚ùå No file uploaded. Exiting...\")\n",
        "    else:\n",
        "        csv_file = list(uploaded.keys())[0]\n",
        "        print(f\"\\n‚úì File uploaded: {csv_file}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"‚öôÔ∏è  CONFIGURATION\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"How many samples do you want to test?\")\n",
        "        print(\"  - Enter a number (e.g., 30) for testing subset\")\n",
        "        print(\"  - Press Enter to test ALL samples\")\n",
        "        print(\"  - Recommended: Start with 30 samples to test model loading\")\n",
        "        print(\"-\"*80)\n",
        "\n",
        "        sample_input = input(\"Sample size: \").strip()\n",
        "        sample_size = int(sample_input) if sample_input.isdigit() else None\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Do you have teacher model metrics for comparison?\")\n",
        "        print(\"  - Enter the filename (e.g., qwen72b_metrics_20260215_173746.json)\")\n",
        "        print(\"  - Press Enter to skip comparison\")\n",
        "        print(\"-\"*80)\n",
        "\n",
        "        teacher_file = input(\"Teacher metrics file: \").strip()\n",
        "        teacher_metrics_file = teacher_file if teacher_file else None\n",
        "\n",
        "        print(\"\\nüöÄ Starting evaluation with local inference...\")\n",
        "        results_df, metrics = test_student_model(csv_file, sample_size, teacher_metrics_file)\n",
        "\n",
        "        print(\"\\nüéâ Student model evaluation complete!\")\n",
        "        print(\"üí° The 1.5B model is now running locally in your Colab environment\")\n",
        "        print(\"üí° Use these results to assess knowledge distillation effectiveness\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7ddd66ba818a452f960fde3c52467c2a",
            "94323d6c0617440d80dc36f0a3626985",
            "6d7cd5308bbc4aeea3dbe0e4a4563ca9",
            "daf02100154442a9be3383d736402f83",
            "0198a22d3e7648f79af6cc0da2b8df72",
            "33c2e2348be34460b4973cc389ce2b93",
            "b3948fe26274425e885b04fd3f3977c6",
            "232d0768ec124b139c8c3de7b757c9d3",
            "069c703a6f204f3f956c41b4f756afa7",
            "99b11eb6aedc4ce5b98bc925654c8561",
            "c6f236e913c74e3a933462abb6d9bf0b"
          ]
        },
        "id": "G9e4WM_NiC_U",
        "outputId": "0f68ae4d-75e4-4117-aa25-fe27b1873b33"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "                    QWEN2.5-1.5B LOCAL INFERENCE SETUP\n",
            "================================================================================\n",
            "\n",
            "üñ•Ô∏è  Device: cuda\n",
            "üì¶ Model: Qwen/Qwen2.5-1.5B-Instruct\n",
            "\n",
            "================================================================================\n",
            "‚öôÔ∏è  SYSTEM CHECK\n",
            "================================================================================\n",
            "PyTorch version: 2.9.0+cu128\n",
            "CUDA available: True\n",
            "CUDA version: 12.8\n",
            "GPU: Tesla T4\n",
            "GPU Memory: 14.56 GB\n",
            "================================================================================\n",
            "\n",
            "üì§ Upload your UPSC dataset CSV file (with ground truth labels)\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f372f6e7-cad6-4377-861f-8a437098a08c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f372f6e7-cad6-4377-861f-8a437098a08c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving upsc_dataset_langchain_20260213_095213.csv to upsc_dataset_langchain_20260213_095213 (5).csv\n",
            "\n",
            "‚úì File uploaded: upsc_dataset_langchain_20260213_095213 (5).csv\n",
            "\n",
            "================================================================================\n",
            "‚öôÔ∏è  CONFIGURATION\n",
            "================================================================================\n",
            "How many samples do you want to test?\n",
            "  - Enter a number (e.g., 30) for testing subset\n",
            "  - Press Enter to test ALL samples\n",
            "  - Recommended: Start with 30 samples to test model loading\n",
            "--------------------------------------------------------------------------------\n",
            "Sample size: 100\n",
            "\n",
            "================================================================================\n",
            "Do you have teacher model metrics for comparison?\n",
            "  - Enter the filename (e.g., qwen72b_metrics_20260215_173746.json)\n",
            "  - Press Enter to skip comparison\n",
            "--------------------------------------------------------------------------------\n",
            "Teacher metrics file: \n",
            "\n",
            "üöÄ Starting evaluation with local inference...\n",
            "\n",
            "================================================================================\n",
            "                    QWEN2.5-1.5B STUDENT MODEL TESTING\n",
            "================================================================================\n",
            "\n",
            "üìÇ Loading dataset...\n",
            "‚úì Loaded 447 rows from upsc_dataset_langchain_20260213_095213 (5).csv\n",
            "‚úì Sampled 100 rows for testing\n",
            "\n",
            "ü§ñ Initializing Qwen2.5-1.5B evaluator...\n",
            "\n",
            "üîÑ Loading Qwen/Qwen2.5-1.5B-Instruct...\n",
            "‚è≥ This may take a few minutes on first run...\n",
            "  üìù Loading tokenizer...\n",
            "  ‚úì Tokenizer loaded: 151665 tokens in vocabulary\n",
            "  ‚úì Special tokens: EOS=<|im_end|>, PAD=<|endoftext|>\n",
            "  ü§ñ Loading model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/338 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ddd66ba818a452f960fde3c52467c2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  üîç Running verification checks...\n",
            "  ‚úì Total parameters: 1,543,714,304 (1.54B)\n",
            "  ‚úì Trainable parameters: 1,543,714,304\n",
            "  ‚úì Model in eval mode: True\n",
            "  ‚úì Model device: cuda:0\n",
            "  ‚úì Model dtype: torch.float16\n",
            "  ‚úì GPU Memory Allocated: 2.88 GB\n",
            "  ‚úì GPU Memory Reserved: 2.93 GB\n",
            "\n",
            "  üß™ Running test inference...\n",
            "  Test response: 'SUCCESS'\n",
            "  ‚úÖ Test inference SUCCESSFUL!\n",
            "  ‚úì Model is ready for evaluation\n",
            "\n",
            "‚úÖ Model loaded and verified successfully on cuda!\n",
            "\n",
            "================================================================================\n",
            "üè• MODEL HEALTH CHECK\n",
            "================================================================================\n",
            "‚úì Model object exists\n",
            "‚úì Tokenizer object exists\n",
            "‚úì Model on correct device: cuda:0\n",
            "‚úì Model in eval mode\n",
            "‚úì Model can accept tokenized inputs\n",
            "‚úì Model can generate outputs\n",
            "‚úì Sufficient GPU memory: 11.68 GB free\n",
            "\n",
            "================================================================================\n",
            "üìä Health Check: 7/7 checks passed\n",
            "================================================================================\n",
            "\n",
            "\n",
            "üß™ Testing classification with sample content...\n",
            "\n",
            "üîç DEBUG Response #1:\n",
            "Raw output: ```json\n",
            "{\n",
            "  \"relevant\": true,\n",
            "  \"gs_paper\": \"GS2\",\n",
            "  \"syllabus_topic\": \"governance and public policy\",\n",
            "  \"confidence\": 0.85\n",
            "}\n",
            "```\n",
            "üìã Test classification result: {'relevant': True, 'gs_paper': 'GS2', 'syllabus_topic': 'governance and public policy', 'confidence': 0.85}\n",
            "   Expected: relevant=True, gs_paper=GS2\n",
            "   Got: relevant=True, gs_paper=GS2\n",
            "   ‚úÖ Model correctly identified relevant content!\n",
            "\n",
            "‚úÖ All systems ready - proceeding with evaluation...\n",
            "\n",
            "\n",
            "üîÑ Starting evaluation on 100 samples...\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:   1%|          | 1/100 [00:01<03:13,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç DEBUG Response #2:\n",
            "Raw output: ```json\n",
            "{\n",
            "  \"relevant\": true,\n",
            "  \"gs_paper\": \"GS2\",\n",
            "  \"syllabus_topic\": \"governance and public policy\",\n",
            "  \"confidence\": 0.85\n",
            "}\n",
            "```\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   2%|‚ñè         | 2/100 [00:03<03:03,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç DEBUG Response #3:\n",
            "Raw output: ```json\n",
            "{\n",
            "  \"relevant\": false,\n",
            "  \"gs_paper\": \"Not Applicable\",\n",
            "  \"syllabus_topic\": \"Not Applicable\",\n",
            "  \"confidence\": 0.90\n",
            "}\n",
            "```\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:   5%|‚ñå         | 5/100 [00:10<03:17,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[5/100] ID: UPSC_0070_0_20260213\n",
            "  GT: Relevant=False, Paper=Not Applicable\n",
            "  Pred: Relevant=True, Paper=GS2\n",
            "  Match: Relevance ‚úó | GS Paper ‚úó | Conf: 0.850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  10%|‚ñà         | 10/100 [00:20<03:07,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[10/100] ID: UPSC_0284_0_20260213\n",
            "  GT: Relevant=True, Paper=GS2\n",
            "  Pred: Relevant=True, Paper=GS2\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Conf: 0.850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  15%|‚ñà‚ñå        | 15/100 [00:29<02:43,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[15/100] ID: UPSC_0335_0_20260213\n",
            "  GT: Relevant=False, Paper=Not Applicable\n",
            "  Pred: Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Conf: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  20%|‚ñà‚ñà        | 20/100 [00:39<02:31,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[20/100] ID: UPSC_0077_0_20260213\n",
            "  GT: Relevant=False, Paper=Not Applicable\n",
            "  Pred: Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Conf: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  25%|‚ñà‚ñà‚ñå       | 25/100 [00:49<02:27,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[25/100] ID: UPSC_0107_0_20260213\n",
            "  GT: Relevant=False, Paper=Not Applicable\n",
            "  Pred: Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Conf: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  30%|‚ñà‚ñà‚ñà       | 30/100 [01:03<03:40,  3.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[30/100] ID: UPSC_0039_0_20260213\n",
            "  GT: Relevant=False, Paper=Not Applicable\n",
            "  Pred: Relevant=True, Paper=GS2\n",
            "  Match: Relevance ‚úó | GS Paper ‚úó | Conf: 0.700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  35%|‚ñà‚ñà‚ñà‚ñå      | 35/100 [01:13<02:22,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[35/100] ID: UPSC_0124_0_20260213\n",
            "  GT: Relevant=True, Paper=GS3\n",
            "  Pred: Relevant=True, Paper=GS2\n",
            "  Match: Relevance ‚úì | GS Paper ‚úó | Conf: 0.850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  40%|‚ñà‚ñà‚ñà‚ñà      | 40/100 [01:23<02:01,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[40/100] ID: UPSC_0205_0_20260213\n",
            "  GT: Relevant=True, Paper=GS2\n",
            "  Pred: Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úó | GS Paper ‚úó | Conf: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 45/100 [01:35<02:10,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[45/100] ID: UPSC_0198_0_20260213\n",
            "  GT: Relevant=True, Paper=GS2\n",
            "  Pred: Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úó | GS Paper ‚úó | Conf: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 50/100 [01:45<01:45,  2.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[50/100] ID: UPSC_0033_0_20260213\n",
            "  GT: Relevant=False, Paper=Not Applicable\n",
            "  Pred: Relevant=True, Paper=GS2\n",
            "  Match: Relevance ‚úó | GS Paper ‚úó | Conf: 0.850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 55/100 [01:55<01:29,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[55/100] ID: UPSC_0011_0_20260213\n",
            "  GT: Relevant=False, Paper=Not Applicable\n",
            "  Pred: Relevant=True, Paper=GS2\n",
            "  Match: Relevance ‚úó | GS Paper ‚úó | Conf: 0.850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60/100 [02:04<01:16,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[60/100] ID: UPSC_0000_0_20260213\n",
            "  GT: Relevant=False, Paper=Not Applicable\n",
            "  Pred: Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Conf: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 65/100 [02:14<01:07,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[65/100] ID: UPSC_0159_1_20260213\n",
            "  GT: Relevant=False, Paper=Not Applicable\n",
            "  Pred: Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Conf: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 70/100 [02:24<00:58,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[70/100] ID: UPSC_0321_0_20260213\n",
            "  GT: Relevant=False, Paper=Not Applicable\n",
            "  Pred: Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Conf: 0.900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75/100 [02:39<01:15,  3.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[75/100] ID: UPSC_0042_0_20260213\n",
            "  GT: Relevant=False, Paper=Not Applicable\n",
            "  Pred: Relevant=True, Paper=GS2\n",
            "  Match: Relevance ‚úó | GS Paper ‚úó | Conf: 0.850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 80/100 [02:49<00:43,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[80/100] ID: UPSC_0246_0_20260213\n",
            "  GT: Relevant=True, Paper=GS2\n",
            "  Pred: Relevant=True, Paper=GS2\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Conf: 0.850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 85/100 [02:59<00:30,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[85/100] ID: UPSC_0384_0_20260213\n",
            "  GT: Relevant=True, Paper=GS3\n",
            "  Pred: Relevant=True, Paper=GS2\n",
            "  Match: Relevance ‚úì | GS Paper ‚úó | Conf: 0.850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90/100 [03:09<00:20,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[90/100] ID: UPSC_0024_0_20260213\n",
            "  GT: Relevant=False, Paper=Not Applicable\n",
            "  Pred: Relevant=True, Paper=GS2\n",
            "  Match: Relevance ‚úó | GS Paper ‚úó | Conf: 0.850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 95/100 [03:19<00:10,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[95/100] ID: UPSC_0031_0_20260213\n",
            "  GT: Relevant=False, Paper=Not Applicable\n",
            "  Pred: Relevant=True, Paper=GS2\n",
            "  Match: Relevance ‚úó | GS Paper ‚úó | Conf: 0.850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [03:29<00:00,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[100/100] ID: UPSC_0243_0_20260213\n",
            "  GT: Relevant=True, Paper=GS2\n",
            "  Pred: Relevant=True, Paper=GS2\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Conf: 0.850\n",
            "\n",
            "================================================================================\n",
            "üìà EVALUATION RESULTS\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "üìä Relevance Classification Metrics\n",
            "============================================================\n",
            "Accuracy:  0.5000 (50.00%)\n",
            "Precision: 0.3269\n",
            "Recall:    0.5312\n",
            "F1-Score:  0.4048\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted\n",
            "               Neg    Pos\n",
            "Actual Neg      33     35\n",
            "       Pos      15     17\n",
            "============================================================\n",
            "\n",
            "üìä GS Paper Classification (among relevant items)\n",
            "============================================================\n",
            "Accuracy: 0.4118 (41.18%)\n",
            "Samples:  17\n",
            "============================================================\n",
            "\n",
            "‚è±Ô∏è  PERFORMANCE SUMMARY\n",
            "============================================================\n",
            "Total samples:        100\n",
            "Processing time:      209.49 seconds\n",
            "Avg time per sample:  2.09 seconds\n",
            "Avg confidence:       0.873\n",
            "============================================================\n",
            "\n",
            "üìö BREAKDOWN BY GS PAPER\n",
            "============================================================\n",
            "GS2: 7/17 correct (41.2%)\n",
            "GS3: 0/15 correct (0.0%)\n",
            "============================================================\n",
            "\n",
            "üíæ Detailed results saved: qwen1.5b_student_results_20260215_185038.csv\n",
            "\n",
            "üìä Generating visualizations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Saved confusion matrix: confusion_matrix_relevance_student.png\n",
            "‚úì Saved GS Paper accuracy plot: gs_paper_accuracy_student.png\n",
            "‚úì Metrics summary saved: qwen1.5b_metrics_20260215_185039.json\n",
            "\n",
            "üì• Downloading results...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9b902d03-a903-4a46-b455-5e9ce672a3a2\", \"qwen1.5b_student_results_20260215_185038.csv\", 10637)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_33d94b60-a891-4911-864a-4090e362df61\", \"qwen1.5b_metrics_20260215_185039.json\", 345)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3862610a-efef-477d-8d9f-739fc5f1784e\", \"confusion_matrix_relevance_student.png\", 106170)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3e178571-e6d9-49dd-994a-e9a23675f45f\", \"gs_paper_accuracy_student.png\", 108484)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "‚úÖ TESTING COMPLETE!\n",
            "================================================================================\n",
            "üßπ GPU memory cleared\n",
            "\n",
            "üéâ Student model evaluation complete!\n",
            "üí° The 1.5B model is now running locally in your Colab environment\n",
            "üí° Use these results to assess knowledge distillation effectiveness\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UPSC Dataset Accuracy Testing with Qwen2.5-72B (Teacher Model)\n",
        "# This establishes baseline accuracy before knowledge distillation\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "from google.colab import files\n",
        "from google.colab import userdata\n",
        "import requests\n",
        "from typing import List, Dict, Tuple\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# You can use Hugging Face Inference API or local inference\n",
        "# Option 1: Hugging Face Inference API (easiest)\n",
        "HF_API_KEY = userdata.get('HF_TOKEN')  # Get your key from hf.co/settings/tokens\n",
        "TEACHER_MODEL = \"Qwen/Qwen2.5-72B-Instruct\"\n",
        "\n",
        "# Option 2: For local inference (uncomment if using vLLM or similar)\n",
        "# LOCAL_API_URL = \"http://localhost:8000/v1/chat/completions\"\n",
        "\n",
        "class QwenTeacherEvaluator:\n",
        "    \"\"\"Evaluator class for testing Qwen2.5-72B on UPSC dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str, model_name: str, use_hf_api: bool = True):\n",
        "        self.api_key = api_key\n",
        "        self.model_name = model_name\n",
        "        self.use_hf_api = use_hf_api\n",
        "\n",
        "        if use_hf_api:\n",
        "            # Updated to new HF router endpoint\n",
        "            self.api_url = f\"https://router.huggingface.co/v1/chat/completions\"\n",
        "            self.headers = {\n",
        "                \"Authorization\": f\"Bearer {api_key}\",\n",
        "                \"Content-Type\": \"application/json\"\n",
        "            }\n",
        "\n",
        "    def call_qwen_teacher(self, text_chunk: str) -> Dict:\n",
        "        \"\"\"Call Qwen2.5-72B to classify UPSC relevance.\"\"\"\n",
        "\n",
        "        system_prompt = \"\"\"You are a UPSC CSE Mains examiner evaluating newspaper content for exam relevance.\n",
        "\n",
        "Your task: Analyze the given text and determine if it's relevant for UPSC preparation.\n",
        "\n",
        "RELEVANT content includes:\n",
        "- Policy announcements with governance implications\n",
        "- Court judgments on constitutional matters\n",
        "- Economic reforms/fiscal measures\n",
        "- International relations developments\n",
        "- Social issues with ethical dimensions\n",
        "- Environmental/scientific developments with policy impact\n",
        "- Governance case studies\n",
        "\n",
        "IRRELEVANT content includes:\n",
        "- Celebrity news, entertainment, sports\n",
        "- Simple factual updates without analytical depth\n",
        "- Advertisements, promotional content\n",
        "- Local incidents without systemic lessons\n",
        "\n",
        "For RELEVANT content, also identify:\n",
        "1. Which GS Paper (GS1, GS2, GS3, or GS4)\n",
        "2. Specific syllabus topic it maps to\n",
        "\n",
        "Return ONLY a JSON object in this format:\n",
        "{\n",
        "  \"relevant\": true or false,\n",
        "  \"gs_paper\": \"GS1\" or \"GS2\" or \"GS3\" or \"GS4\" or \"Not Applicable\",\n",
        "  \"syllabus_topic\": \"specific topic\" or \"Not Applicable\",\n",
        "  \"confidence\": 0.0 to 1.0\n",
        "}\"\"\"\n",
        "\n",
        "        user_message = f\"Analyze this newspaper text for UPSC relevance:\\n\\n{text_chunk[:4000]}\"  # Limit to 4k chars\n",
        "\n",
        "        if self.use_hf_api:\n",
        "            return self._call_hf_api(system_prompt, user_message)\n",
        "        else:\n",
        "            return self._call_local_api(system_prompt, user_message)\n",
        "\n",
        "    def _call_hf_api(self, system_prompt: str, user_message: str) -> Dict:\n",
        "        \"\"\"Call Hugging Face Inference API using new router endpoint.\"\"\"\n",
        "\n",
        "        # New format uses OpenAI-compatible chat completions\n",
        "        payload = {\n",
        "            \"model\": self.model_name,\n",
        "            \"messages\": [\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_message}\n",
        "            ],\n",
        "            \"max_tokens\": 256,\n",
        "            \"temperature\": 0.1,\n",
        "            \"top_p\": 0.9\n",
        "        }\n",
        "\n",
        "        max_retries = 3\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                response = requests.post(\n",
        "                    self.api_url,\n",
        "                    headers=self.headers,\n",
        "                    json=payload,\n",
        "                    timeout=60\n",
        "                )\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    result = response.json()\n",
        "                    # Extract content from chat completion format\n",
        "                    generated_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "                    # Extract JSON from response\n",
        "                    json_start = generated_text.find('{')\n",
        "                    json_end = generated_text.rfind('}') + 1\n",
        "\n",
        "                    if json_start != -1 and json_end > json_start:\n",
        "                        json_str = generated_text[json_start:json_end]\n",
        "                        return json.loads(json_str)\n",
        "                    else:\n",
        "                        return self._default_response()\n",
        "\n",
        "                elif response.status_code == 503:\n",
        "                    print(f\"  ‚è≥ Model loading... retrying in 20s (attempt {attempt+1}/{max_retries})\")\n",
        "                    time.sleep(20)\n",
        "                else:\n",
        "                    print(f\"  ‚ùå API Error {response.status_code}: {response.text}\")\n",
        "                    return self._default_response()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ùå Exception: {e}\")\n",
        "                if attempt < max_retries - 1:\n",
        "                    time.sleep(5)\n",
        "                else:\n",
        "                    return self._default_response()\n",
        "\n",
        "        return self._default_response()\n",
        "\n",
        "    def _call_local_api(self, system_prompt: str, user_message: str) -> Dict:\n",
        "        \"\"\"Call local vLLM or similar API endpoint.\"\"\"\n",
        "        payload = {\n",
        "            \"model\": self.model_name,\n",
        "            \"messages\": [\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_message}\n",
        "            ],\n",
        "            \"temperature\": 0.1,\n",
        "            \"max_tokens\": 256\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                LOCAL_API_URL,\n",
        "                json=payload,\n",
        "                timeout=60\n",
        "            )\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                result = response.json()\n",
        "                content = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "                # Extract JSON\n",
        "                json_start = content.find('{')\n",
        "                json_end = content.rfind('}') + 1\n",
        "\n",
        "                if json_start != -1 and json_end > json_start:\n",
        "                    json_str = content[json_start:json_end]\n",
        "                    return json.loads(json_str)\n",
        "\n",
        "            return self._default_response()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Local API Error: {e}\")\n",
        "            return self._default_response()\n",
        "\n",
        "    def _default_response(self) -> Dict:\n",
        "        \"\"\"Return default response on error.\"\"\"\n",
        "        return {\n",
        "            \"relevant\": False,\n",
        "            \"gs_paper\": \"Not Applicable\",\n",
        "            \"syllabus_topic\": \"Not Applicable\",\n",
        "            \"confidence\": 0.0\n",
        "        }\n",
        "\n",
        "def calculate_metrics(y_true: List, y_pred: List, label_name: str = \"Relevance\") -> Dict:\n",
        "    \"\"\"Calculate comprehensive evaluation metrics.\"\"\"\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average='binary', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"confusion_matrix\": cm,\n",
        "        \"support\": support\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üìä {label_name} Metrics\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall:    {recall:.4f}\")\n",
        "    print(f\"F1-Score:  {f1:.4f}\")\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(f\"                 Predicted\")\n",
        "    print(f\"               Neg    Pos\")\n",
        "    print(f\"Actual Neg    {cm[0][0]:4d}   {cm[0][1]:4d}\")\n",
        "    print(f\"       Pos    {cm[1][0]:4d}   {cm[1][1]:4d}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def plot_confusion_matrix(cm, title, filename):\n",
        "    \"\"\"Plot and save confusion matrix.\"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Negative', 'Positive'],\n",
        "                yticklabels=['Negative', 'Positive'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"‚úì Saved confusion matrix: {filename}\")\n",
        "\n",
        "def plot_gs_paper_accuracy(df_results, filename):\n",
        "    \"\"\"Plot accuracy by GS Paper.\"\"\"\n",
        "    gs_papers = ['GS1', 'GS2', 'GS3', 'GS4']\n",
        "    accuracies = []\n",
        "    counts = []\n",
        "\n",
        "    for paper in gs_papers:\n",
        "        paper_df = df_results[df_results['Ground_Truth_GS_Paper'] == paper]\n",
        "        if len(paper_df) > 0:\n",
        "            correct = (paper_df['Ground_Truth_GS_Paper'] == paper_df['Predicted_GS_Paper']).sum()\n",
        "            accuracy = correct / len(paper_df)\n",
        "            accuracies.append(accuracy * 100)\n",
        "            counts.append(len(paper_df))\n",
        "        else:\n",
        "            accuracies.append(0)\n",
        "            counts.append(0)\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    x = np.arange(len(gs_papers))\n",
        "    width = 0.35\n",
        "\n",
        "    ax1.bar(x - width/2, accuracies, width, label='Accuracy %', color='steelblue')\n",
        "    ax1.set_ylabel('Accuracy (%)', color='steelblue')\n",
        "    ax1.set_xlabel('GS Paper')\n",
        "    ax1.set_title('Qwen2.5-72B: Accuracy by GS Paper')\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(gs_papers)\n",
        "    ax1.legend(loc='upper left')\n",
        "    ax1.set_ylim([0, 105])\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.bar(x + width/2, counts, width, label='Sample Count', color='coral', alpha=0.7)\n",
        "    ax2.set_ylabel('Sample Count', color='coral')\n",
        "    ax2.legend(loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"‚úì Saved GS Paper accuracy plot: {filename}\")\n",
        "\n",
        "def test_teacher_model(csv_file_path: str, sample_size: int = None):\n",
        "    \"\"\"\n",
        "    Test Qwen2.5-72B teacher model on the UPSC dataset.\n",
        "\n",
        "    Args:\n",
        "        csv_file_path: Path to the CSV file with ground truth labels\n",
        "        sample_size: Number of samples to test (None = all samples)\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\" \"*20 + \"QWEN2.5-72B TEACHER MODEL TESTING\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Load dataset\n",
        "    print(\"\\nüìÇ Loading dataset...\")\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "    print(f\"‚úì Loaded {len(df)} rows from {csv_file_path}\")\n",
        "\n",
        "    # Sample if requested\n",
        "    if sample_size and sample_size < len(df):\n",
        "        df = df.sample(n=sample_size, random_state=42)\n",
        "        print(f\"‚úì Sampled {sample_size} rows for testing\")\n",
        "\n",
        "    # Initialize evaluator\n",
        "    print(f\"\\nü§ñ Initializing Qwen2.5-72B evaluator...\")\n",
        "    evaluator = QwenTeacherEvaluator(\n",
        "        api_key=HF_API_KEY,\n",
        "        model_name=TEACHER_MODEL,\n",
        "        use_hf_api=True  # Change to False if using local API\n",
        "    )\n",
        "\n",
        "    # Prepare results storage\n",
        "    predictions = []\n",
        "    ground_truth_relevance = []\n",
        "    predicted_relevance = []\n",
        "    ground_truth_gs_paper = []\n",
        "    predicted_gs_paper = []\n",
        "    confidences = []\n",
        "\n",
        "    print(f\"\\nüîÑ Starting evaluation on {len(df)} samples...\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Evaluate each sample\n",
        "    for idx, row in df.iterrows():\n",
        "        print(f\"\\n[{idx+1}/{len(df)}] Processing ID: {row['ID']}\")\n",
        "\n",
        "        # Get prediction from Qwen\n",
        "        result = evaluator.call_qwen_teacher(row['Text Chunk'])\n",
        "\n",
        "        # Ground truth\n",
        "        gt_relevant = row['Relevant to UPSC']\n",
        "        gt_gs_paper = row['GS Paper'] if gt_relevant else \"Not Applicable\"\n",
        "\n",
        "        # Prediction\n",
        "        pred_relevant = result['relevant']\n",
        "        pred_gs_paper = result['gs_paper']\n",
        "        confidence = result.get('confidence', 0.0)\n",
        "\n",
        "        # Store results\n",
        "        predictions.append({\n",
        "            'ID': row['ID'],\n",
        "            'Source_PDF': row['Source PDF'],\n",
        "            'Ground_Truth_Relevant': gt_relevant,\n",
        "            'Predicted_Relevant': pred_relevant,\n",
        "            'Ground_Truth_GS_Paper': gt_gs_paper,\n",
        "            'Predicted_GS_Paper': pred_gs_paper,\n",
        "            'Confidence': confidence,\n",
        "            'Correct_Relevance': gt_relevant == pred_relevant,\n",
        "            'Correct_GS_Paper': gt_gs_paper == pred_gs_paper if gt_relevant and pred_relevant else False\n",
        "        })\n",
        "\n",
        "        ground_truth_relevance.append(gt_relevant)\n",
        "        predicted_relevance.append(pred_relevant)\n",
        "        ground_truth_gs_paper.append(gt_gs_paper)\n",
        "        predicted_gs_paper.append(pred_gs_paper)\n",
        "        confidences.append(confidence)\n",
        "\n",
        "        # Progress indicator\n",
        "        match_relevance = \"‚úì\" if gt_relevant == pred_relevant else \"‚úó\"\n",
        "        match_paper = \"‚úì\" if gt_gs_paper == pred_gs_paper else \"‚úó\"\n",
        "        print(f\"  Ground Truth: Relevant={gt_relevant}, Paper={gt_gs_paper}\")\n",
        "        print(f\"  Prediction:   Relevant={pred_relevant}, Paper={pred_gs_paper}\")\n",
        "        print(f\"  Match: Relevance {match_relevance} | GS Paper {match_paper} | Confidence: {confidence:.3f}\")\n",
        "\n",
        "        # Rate limiting for HF API\n",
        "        time.sleep(1.5)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    # Create results DataFrame\n",
        "    df_results = pd.DataFrame(predictions)\n",
        "\n",
        "    # Calculate metrics\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üìà EVALUATION RESULTS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Relevance classification metrics\n",
        "    relevance_metrics = calculate_metrics(\n",
        "        ground_truth_relevance,\n",
        "        predicted_relevance,\n",
        "        \"Relevance Classification\"\n",
        "    )\n",
        "\n",
        "    # GS Paper classification metrics (only for relevant items)\n",
        "    relevant_mask = [gt and pred for gt, pred in zip(ground_truth_relevance, predicted_relevance)]\n",
        "    if sum(relevant_mask) > 0:\n",
        "        gs_paper_gt_filtered = [gt for gt, mask in zip(ground_truth_gs_paper, relevant_mask) if mask]\n",
        "        gs_paper_pred_filtered = [pred for pred, mask in zip(predicted_gs_paper, relevant_mask) if mask]\n",
        "\n",
        "        # Convert to binary for metrics (correct paper vs incorrect)\n",
        "        gs_paper_binary_gt = [1] * len(gs_paper_gt_filtered)\n",
        "        gs_paper_binary_pred = [1 if gt == pred else 0\n",
        "                                for gt, pred in zip(gs_paper_gt_filtered, gs_paper_pred_filtered)]\n",
        "\n",
        "        gs_paper_accuracy = sum(gs_paper_binary_pred) / len(gs_paper_binary_pred)\n",
        "\n",
        "        print(f\"üìä GS Paper Classification (among relevant items)\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Accuracy: {gs_paper_accuracy:.4f} ({gs_paper_accuracy*100:.2f}%)\")\n",
        "        print(f\"Samples:  {len(gs_paper_binary_pred)}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Summary statistics\n",
        "    print(f\"‚è±Ô∏è  PERFORMANCE SUMMARY\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Total samples:        {len(df)}\")\n",
        "    print(f\"Processing time:      {elapsed_time:.2f} seconds\")\n",
        "    print(f\"Avg time per sample:  {elapsed_time/len(df):.2f} seconds\")\n",
        "    print(f\"Avg confidence:       {np.mean(confidences):.3f}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Breakdown by GS Paper\n",
        "    print(f\"üìö BREAKDOWN BY GS PAPER\")\n",
        "    print(f\"{'='*60}\")\n",
        "    for paper in ['GS1', 'GS2', 'GS3', 'GS4']:\n",
        "        paper_df = df_results[df_results['Ground_Truth_GS_Paper'] == paper]\n",
        "        if len(paper_df) > 0:\n",
        "            correct = (paper_df['Ground_Truth_GS_Paper'] == paper_df['Predicted_GS_Paper']).sum()\n",
        "            accuracy = correct / len(paper_df)\n",
        "            print(f\"{paper}: {correct}/{len(paper_df)} correct ({accuracy*100:.1f}%)\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Save results\n",
        "    output_csv = f\"qwen72b_teacher_results_{time.strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "    df_results.to_csv(output_csv, index=False)\n",
        "    print(f\"üíæ Detailed results saved: {output_csv}\")\n",
        "\n",
        "    # Generate visualizations\n",
        "    print(f\"\\nüìä Generating visualizations...\")\n",
        "    plot_confusion_matrix(\n",
        "        relevance_metrics['confusion_matrix'],\n",
        "        'Qwen2.5-72B: Relevance Classification Confusion Matrix',\n",
        "        'confusion_matrix_relevance.png'\n",
        "    )\n",
        "\n",
        "    plot_gs_paper_accuracy(\n",
        "        df_results,\n",
        "        'gs_paper_accuracy.png'\n",
        "    )\n",
        "\n",
        "    # Save metrics summary\n",
        "    metrics_summary = {\n",
        "        'model': TEACHER_MODEL,\n",
        "        'total_samples': len(df),\n",
        "        'processing_time_seconds': elapsed_time,\n",
        "        'relevance_accuracy': float(relevance_metrics['accuracy']),\n",
        "        'relevance_precision': float(relevance_metrics['precision']),\n",
        "        'relevance_recall': float(relevance_metrics['recall']),\n",
        "        'relevance_f1': float(relevance_metrics['f1_score']),\n",
        "        'avg_confidence': float(np.mean(confidences)),\n",
        "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "    }\n",
        "\n",
        "    metrics_file = f\"qwen72b_metrics_{time.strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    with open(metrics_file, 'w') as f:\n",
        "        json.dump(metrics_summary, f, indent=2)\n",
        "\n",
        "    print(f\"‚úì Metrics summary saved: {metrics_file}\")\n",
        "\n",
        "    # Download all files\n",
        "    print(f\"\\nüì• Downloading results...\")\n",
        "    files.download(output_csv)\n",
        "    files.download(metrics_file)\n",
        "    files.download('confusion_matrix_relevance.png')\n",
        "    files.download('gs_paper_accuracy.png')\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"‚úÖ TESTING COMPLETE!\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    return df_results, metrics_summary\n",
        "\n",
        "# --- MAIN EXECUTION ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nüì§ Upload your UPSC dataset CSV file (with ground truth labels)\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"\\n‚ùå No file uploaded. Exiting...\")\n",
        "    else:\n",
        "        csv_file = list(uploaded.keys())[0]\n",
        "        print(f\"\\n‚úì File uploaded: {csv_file}\")\n",
        "\n",
        "        # Ask for sample size\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"‚öôÔ∏è  CONFIGURATION\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"How many samples do you want to test?\")\n",
        "        print(\"  - Enter a number (e.g., 100) for testing subset\")\n",
        "        print(\"  - Press Enter to test ALL samples\")\n",
        "        print(\"-\"*80)\n",
        "\n",
        "        sample_input = input(\"Sample size: \").strip()\n",
        "        sample_size = int(sample_input) if sample_input.isdigit() else None\n",
        "\n",
        "        # Run evaluation\n",
        "        results_df, metrics = test_teacher_model(csv_file, sample_size)\n",
        "\n",
        "        print(\"\\nüéâ Teacher model baseline established!\")\n",
        "        print(\"Next step: Use these results for knowledge distillation to Qwen2.5-1.5B\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xcboRtHYfjxR",
        "outputId": "85a9954a-362b-4fa6-809c-a9a9ad67c09d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì§ Upload your UPSC dataset CSV file (with ground truth labels)\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fb27641b-ba4b-4a6a-a3ef-74631c6f725e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fb27641b-ba4b-4a6a-a3ef-74631c6f725e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving upsc_dataset_langchain_20260213_095213.csv to upsc_dataset_langchain_20260213_095213 (2).csv\n",
            "\n",
            "‚úì File uploaded: upsc_dataset_langchain_20260213_095213 (2).csv\n",
            "\n",
            "================================================================================\n",
            "‚öôÔ∏è  CONFIGURATION\n",
            "================================================================================\n",
            "How many samples do you want to test?\n",
            "  - Enter a number (e.g., 100) for testing subset\n",
            "  - Press Enter to test ALL samples\n",
            "--------------------------------------------------------------------------------\n",
            "Sample size: 30\n",
            "================================================================================\n",
            "                    QWEN2.5-72B TEACHER MODEL TESTING\n",
            "================================================================================\n",
            "\n",
            "üìÇ Loading dataset...\n",
            "‚úì Loaded 447 rows from upsc_dataset_langchain_20260213_095213 (2).csv\n",
            "‚úì Sampled 30 rows for testing\n",
            "\n",
            "ü§ñ Initializing Qwen2.5-72B evaluator...\n",
            "\n",
            "üîÑ Starting evaluation on 30 samples...\n",
            "================================================================================\n",
            "\n",
            "[285/30] Processing ID: UPSC_0244_1_20260213\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=True, Paper=GS2\n",
            "  Match: Relevance ‚úó | GS Paper ‚úó | Confidence: 0.850\n",
            "\n",
            "[378/30] Processing ID: UPSC_0320_0_20260213\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-85890109.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;31m# Run evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mresults_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_teacher_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüéâ Teacher model baseline established!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-85890109.py\u001b[0m in \u001b[0;36mtest_teacher_model\u001b[0;34m(csv_file_path, sample_size)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# Get prediction from Qwen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_qwen_teacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text Chunk'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;31m# Ground truth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-85890109.py\u001b[0m in \u001b[0;36mcall_qwen_teacher\u001b[0;34m(self, text_chunk)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_hf_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_hf_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msystem_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_local_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msystem_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-85890109.py\u001b[0m in \u001b[0;36m_call_hf_api\u001b[0;34m(self, system_prompt, user_message)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 response = requests.post(\n\u001b[0m\u001b[1;32m    101\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1249\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UPSC Dataset Accuracy Testing with Qwen2.5-1.5B (Student Model)\n",
        "# Updated version with multiple API options\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "from google.colab import files\n",
        "from google.colab import userdata\n",
        "import requests\n",
        "from typing import List, Dict, Tuple\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Multiple API options - the script will try them in order\n",
        "\n",
        "# Option 1: HuggingFace Inference API (Serverless)\n",
        "HF_API_KEY = userdata.get('HF_TOKEN')\n",
        "STUDENT_MODEL = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "\n",
        "# Option 2: Alternative smaller models that are available\n",
        "ALTERNATIVE_MODELS = [\n",
        "    \"Qwen/Qwen2.5-3B-Instruct\",      # Slightly larger but more available\n",
        "    \"Qwen/Qwen2.5-7B-Instruct\",      # Fallback option\n",
        "    \"meta-llama/Llama-3.2-1B-Instruct\",  # Alternative 1B model\n",
        "]\n",
        "\n",
        "class QwenStudentEvaluator:\n",
        "    \"\"\"Evaluator class for testing Qwen2.5-1.5B or alternative models on UPSC dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str, model_name: str, use_serverless: bool = True):\n",
        "        self.api_key = api_key\n",
        "        self.model_name = model_name\n",
        "        self.use_serverless = use_serverless\n",
        "        self.api_type = None\n",
        "\n",
        "        # Try different API endpoints\n",
        "        self._setup_api()\n",
        "\n",
        "    def _setup_api(self):\n",
        "        \"\"\"Setup API endpoint - try serverless first, then router.\"\"\"\n",
        "\n",
        "        if self.use_serverless:\n",
        "            # Try HuggingFace Serverless Inference API first\n",
        "            self.api_url = f\"https://api-inference.huggingface.co/models/{self.model_name}\"\n",
        "            self.headers = {\n",
        "                \"Authorization\": f\"Bearer {self.api_key}\",\n",
        "                \"Content-Type\": \"application/json\"\n",
        "            }\n",
        "            self.api_type = \"serverless\"\n",
        "            print(f\"‚úì Using HuggingFace Serverless API: {self.model_name}\")\n",
        "        else:\n",
        "            # Router endpoint (may not support all models)\n",
        "            self.api_url = f\"https://router.huggingface.co/v1/chat/completions\"\n",
        "            self.headers = {\n",
        "                \"Authorization\": f\"Bearer {self.api_key}\",\n",
        "                \"Content-Type\": \"application/json\"\n",
        "            }\n",
        "            self.api_type = \"router\"\n",
        "            print(f\"‚úì Using HuggingFace Router API: {self.model_name}\")\n",
        "\n",
        "    def call_qwen_student(self, text_chunk: str) -> Dict:\n",
        "        \"\"\"Call Qwen2.5-1.5B (or alternative) to classify UPSC relevance.\"\"\"\n",
        "\n",
        "        system_prompt = \"\"\"You are a UPSC CSE Mains examiner evaluating newspaper content for exam relevance.\n",
        "\n",
        "Your task: Analyze the given text and determine if it's relevant for UPSC preparation.\n",
        "\n",
        "RELEVANT content includes:\n",
        "- Policy announcements with governance implications\n",
        "- Court judgments on constitutional matters\n",
        "- Economic reforms/fiscal measures\n",
        "- International relations developments\n",
        "- Social issues with ethical dimensions\n",
        "- Environmental/scientific developments with policy impact\n",
        "- Governance case studies\n",
        "\n",
        "IRRELEVANT content includes:\n",
        "- Celebrity news, entertainment, sports\n",
        "- Simple factual updates without analytical depth\n",
        "- Advertisements, promotional content\n",
        "- Local incidents without systemic lessons\n",
        "\n",
        "For RELEVANT content, also identify:\n",
        "1. Which GS Paper (GS1, GS2, GS3, or GS4)\n",
        "2. Specific syllabus topic it maps to\n",
        "\n",
        "Return ONLY a JSON object in this format:\n",
        "{\n",
        "  \"relevant\": true or false,\n",
        "  \"gs_paper\": \"GS1\" or \"GS2\" or \"GS3\" or \"GS4\" or \"Not Applicable\",\n",
        "  \"syllabus_topic\": \"specific topic\" or \"Not Applicable\",\n",
        "  \"confidence\": 0.0 to 1.0\n",
        "}\"\"\"\n",
        "\n",
        "        user_message = f\"Analyze this newspaper text for UPSC relevance:\\n\\n{text_chunk[:4000]}\"\n",
        "\n",
        "        if self.api_type == \"serverless\":\n",
        "            return self._call_serverless_api(system_prompt, user_message)\n",
        "        else:\n",
        "            return self._call_router_api(system_prompt, user_message)\n",
        "\n",
        "    def _call_serverless_api(self, system_prompt: str, user_message: str) -> Dict:\n",
        "        \"\"\"Call HuggingFace Serverless Inference API.\"\"\"\n",
        "\n",
        "        # Format for text generation models\n",
        "        full_prompt = f\"{system_prompt}\\n\\nUser: {user_message}\\n\\nAssistant:\"\n",
        "\n",
        "        payload = {\n",
        "            \"inputs\": full_prompt,\n",
        "            \"parameters\": {\n",
        "                \"max_new_tokens\": 256,\n",
        "                \"temperature\": 0.1,\n",
        "                \"top_p\": 0.9,\n",
        "                \"return_full_text\": False\n",
        "            }\n",
        "        }\n",
        "\n",
        "        max_retries = 3\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                response = requests.post(\n",
        "                    self.api_url,\n",
        "                    headers=self.headers,\n",
        "                    json=payload,\n",
        "                    timeout=60\n",
        "                )\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    result = response.json()\n",
        "\n",
        "                    # Handle different response formats\n",
        "                    if isinstance(result, list) and len(result) > 0:\n",
        "                        generated_text = result[0].get('generated_text', '')\n",
        "                    elif isinstance(result, dict):\n",
        "                        generated_text = result.get('generated_text', '')\n",
        "                    else:\n",
        "                        generated_text = str(result)\n",
        "\n",
        "                    # Extract JSON from response\n",
        "                    json_start = generated_text.find('{')\n",
        "                    json_end = generated_text.rfind('}') + 1\n",
        "\n",
        "                    if json_start != -1 and json_end > json_start:\n",
        "                        json_str = generated_text[json_start:json_end]\n",
        "                        return json.loads(json_str)\n",
        "                    else:\n",
        "                        return self._default_response()\n",
        "\n",
        "                elif response.status_code == 503:\n",
        "                    print(f\"  ‚è≥ Model loading... retrying in 20s (attempt {attempt+1}/{max_retries})\")\n",
        "                    time.sleep(20)\n",
        "                else:\n",
        "                    print(f\"  ‚ùå API Error {response.status_code}: {response.text[:200]}\")\n",
        "                    return self._default_response()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ùå Exception: {str(e)[:200]}\")\n",
        "                if attempt < max_retries - 1:\n",
        "                    time.sleep(5)\n",
        "                else:\n",
        "                    return self._default_response()\n",
        "\n",
        "        return self._default_response()\n",
        "\n",
        "    def _call_router_api(self, system_prompt: str, user_message: str) -> Dict:\n",
        "        \"\"\"Call HuggingFace Router API (chat completions).\"\"\"\n",
        "\n",
        "        payload = {\n",
        "            \"model\": self.model_name,\n",
        "            \"messages\": [\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_message}\n",
        "            ],\n",
        "            \"max_tokens\": 256,\n",
        "            \"temperature\": 0.1,\n",
        "            \"top_p\": 0.9\n",
        "        }\n",
        "\n",
        "        max_retries = 3\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                response = requests.post(\n",
        "                    self.api_url,\n",
        "                    headers=self.headers,\n",
        "                    json=payload,\n",
        "                    timeout=60\n",
        "                )\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    result = response.json()\n",
        "                    generated_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "                    # Extract JSON from response\n",
        "                    json_start = generated_text.find('{')\n",
        "                    json_end = generated_text.rfind('}') + 1\n",
        "\n",
        "                    if json_start != -1 and json_end > json_start:\n",
        "                        json_str = generated_text[json_start:json_end]\n",
        "                        return json.loads(json_str)\n",
        "                    else:\n",
        "                        return self._default_response()\n",
        "\n",
        "                elif response.status_code == 503:\n",
        "                    print(f\"  ‚è≥ Model loading... retrying in 20s (attempt {attempt+1}/{max_retries})\")\n",
        "                    time.sleep(20)\n",
        "                elif response.status_code == 400:\n",
        "                    print(f\"  ‚ùå Model not supported on router API, trying serverless...\")\n",
        "                    # Switch to serverless and retry\n",
        "                    self.api_type = \"serverless\"\n",
        "                    self._setup_api()\n",
        "                    return self._call_serverless_api(system_prompt, user_message)\n",
        "                else:\n",
        "                    print(f\"  ‚ùå API Error {response.status_code}: {response.text[:200]}\")\n",
        "                    return self._default_response()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ùå Exception: {str(e)[:200]}\")\n",
        "                if attempt < max_retries - 1:\n",
        "                    time.sleep(5)\n",
        "                else:\n",
        "                    return self._default_response()\n",
        "\n",
        "        return self._default_response()\n",
        "\n",
        "    def _default_response(self) -> Dict:\n",
        "        \"\"\"Return default response on error.\"\"\"\n",
        "        return {\n",
        "            \"relevant\": False,\n",
        "            \"gs_paper\": \"Not Applicable\",\n",
        "            \"syllabus_topic\": \"Not Applicable\",\n",
        "            \"confidence\": 0.0\n",
        "        }\n",
        "\n",
        "def calculate_metrics(y_true: List, y_pred: List, label_name: str = \"Relevance\") -> Dict:\n",
        "    \"\"\"Calculate comprehensive evaluation metrics.\"\"\"\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average='binary', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"confusion_matrix\": cm,\n",
        "        \"support\": support\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üìä {label_name} Metrics\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall:    {recall:.4f}\")\n",
        "    print(f\"F1-Score:  {f1:.4f}\")\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(f\"                 Predicted\")\n",
        "    print(f\"               Neg    Pos\")\n",
        "    print(f\"Actual Neg    {cm[0][0]:4d}   {cm[0][1]:4d}\")\n",
        "    print(f\"       Pos    {cm[1][0]:4d}   {cm[1][1]:4d}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def plot_confusion_matrix(cm, title, filename):\n",
        "    \"\"\"Plot and save confusion matrix.\"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Negative', 'Positive'],\n",
        "                yticklabels=['Negative', 'Positive'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"‚úì Saved confusion matrix: {filename}\")\n",
        "\n",
        "def plot_gs_paper_accuracy(df_results, filename):\n",
        "    \"\"\"Plot accuracy by GS Paper.\"\"\"\n",
        "    gs_papers = ['GS1', 'GS2', 'GS3', 'GS4']\n",
        "    accuracies = []\n",
        "    counts = []\n",
        "\n",
        "    for paper in gs_papers:\n",
        "        paper_df = df_results[df_results['Ground_Truth_GS_Paper'] == paper]\n",
        "        if len(paper_df) > 0:\n",
        "            correct = (paper_df['Ground_Truth_GS_Paper'] == paper_df['Predicted_GS_Paper']).sum()\n",
        "            accuracy = correct / len(paper_df)\n",
        "            accuracies.append(accuracy * 100)\n",
        "            counts.append(len(paper_df))\n",
        "        else:\n",
        "            accuracies.append(0)\n",
        "            counts.append(0)\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    x = np.arange(len(gs_papers))\n",
        "    width = 0.35\n",
        "\n",
        "    ax1.bar(x - width/2, accuracies, width, label='Accuracy %', color='steelblue')\n",
        "    ax1.set_ylabel('Accuracy (%)', color='steelblue')\n",
        "    ax1.set_xlabel('GS Paper')\n",
        "    ax1.set_title('Qwen2.5-1.5B: Accuracy by GS Paper')\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(gs_papers)\n",
        "    ax1.legend(loc='upper left')\n",
        "    ax1.set_ylim([0, 105])\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.bar(x + width/2, counts, width, label='Sample Count', color='coral', alpha=0.7)\n",
        "    ax2.set_ylabel('Sample Count', color='coral')\n",
        "    ax2.legend(loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"‚úì Saved GS Paper accuracy plot: {filename}\")\n",
        "\n",
        "def plot_comparison_with_teacher(student_metrics, teacher_metrics_file=None):\n",
        "    \"\"\"Create comparison plots between student and teacher models.\"\"\"\n",
        "\n",
        "    if teacher_metrics_file:\n",
        "        try:\n",
        "            with open(teacher_metrics_file, 'r') as f:\n",
        "                teacher_metrics = json.load(f)\n",
        "        except:\n",
        "            print(\"‚ö†Ô∏è  Could not load teacher metrics for comparison\")\n",
        "            return\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  No teacher metrics file provided - skipping comparison\")\n",
        "        return\n",
        "\n",
        "    # Comparison bar chart\n",
        "    metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "    teacher_values = [\n",
        "        teacher_metrics['relevance_accuracy'],\n",
        "        teacher_metrics['relevance_precision'],\n",
        "        teacher_metrics['relevance_recall'],\n",
        "        teacher_metrics['relevance_f1']\n",
        "    ]\n",
        "    student_values = [\n",
        "        student_metrics['relevance_accuracy'],\n",
        "        student_metrics['relevance_precision'],\n",
        "        student_metrics['relevance_recall'],\n",
        "        student_metrics['relevance_f1']\n",
        "    ]\n",
        "\n",
        "    x = np.arange(len(metrics_names))\n",
        "    width = 0.35\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    bars1 = ax.bar(x - width/2, teacher_values, width, label='Teacher (72B)', color='#2E75B6')\n",
        "    bars2 = ax.bar(x + width/2, student_values, width, label='Student (1.5B)', color='#70AD47')\n",
        "\n",
        "    ax.set_ylabel('Score')\n",
        "    ax.set_title('Teacher vs Student Model Performance Comparison')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(metrics_names)\n",
        "    ax.legend()\n",
        "    ax.set_ylim([0, 1.1])\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bars in [bars1, bars2]:\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.annotate(f'{height:.3f}',\n",
        "                       xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                       xytext=(0, 3),\n",
        "                       textcoords=\"offset points\",\n",
        "                       ha='center', va='bottom',\n",
        "                       fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('teacher_vs_student_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"‚úì Saved comparison plot: teacher_vs_student_comparison.png\")\n",
        "\n",
        "    # Performance gap analysis\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üìä PERFORMANCE GAP ANALYSIS\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Model Size Reduction: 72B ‚Üí 1.5B (97.9% smaller)\")\n",
        "    print(f\"\\nMetric Differences (Student - Teacher):\")\n",
        "    print(f\"  Accuracy:  {student_values[0] - teacher_values[0]:+.4f} ({(student_values[0] - teacher_values[0])*100:+.2f}%)\")\n",
        "    print(f\"  Precision: {student_values[1] - teacher_values[1]:+.4f} ({(student_values[1] - teacher_values[1])*100:+.2f}%)\")\n",
        "    print(f\"  Recall:    {student_values[2] - teacher_values[2]:+.4f} ({(student_values[2] - teacher_values[2])*100:+.2f}%)\")\n",
        "    print(f\"  F1-Score:  {student_values[3] - teacher_values[3]:+.4f} ({(student_values[3] - teacher_values[3])*100:+.2f}%)\")\n",
        "\n",
        "    # Speed comparison\n",
        "    if 'processing_time_seconds' in teacher_metrics and 'processing_time_seconds' in student_metrics:\n",
        "        teacher_time = teacher_metrics['processing_time_seconds'] / teacher_metrics['total_samples']\n",
        "        student_time = student_metrics['processing_time_seconds'] / student_metrics['total_samples']\n",
        "        speedup = teacher_time / student_time\n",
        "        print(f\"\\nSpeed Comparison:\")\n",
        "        print(f\"  Teacher avg time: {teacher_time:.2f}s per sample\")\n",
        "        print(f\"  Student avg time: {student_time:.2f}s per sample\")\n",
        "        print(f\"  Speedup: {speedup:.2f}x faster\")\n",
        "\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "def test_student_model(csv_file_path: str, sample_size: int = None, teacher_metrics_file: str = None, model_name: str = STUDENT_MODEL):\n",
        "    \"\"\"\n",
        "    Test Qwen2.5-1.5B student model on the UPSC dataset.\n",
        "\n",
        "    Args:\n",
        "        csv_file_path: Path to the CSV file with ground truth labels\n",
        "        sample_size: Number of samples to test (None = all samples)\n",
        "        teacher_metrics_file: Path to teacher model metrics JSON for comparison\n",
        "        model_name: Model to use (default: Qwen/Qwen2.5-1.5B-Instruct)\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\" \"*20 + \"QWEN2.5-1.5B STUDENT MODEL TESTING\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Load dataset\n",
        "    print(\"\\nüìÇ Loading dataset...\")\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "    print(f\"‚úì Loaded {len(df)} rows from {csv_file_path}\")\n",
        "\n",
        "    # Sample if requested\n",
        "    if sample_size and sample_size < len(df):\n",
        "        df = df.sample(n=sample_size, random_state=42)\n",
        "        print(f\"‚úì Sampled {sample_size} rows for testing\")\n",
        "\n",
        "    # Initialize evaluator - try serverless first\n",
        "    print(f\"\\nü§ñ Initializing {model_name} evaluator...\")\n",
        "    evaluator = QwenStudentEvaluator(\n",
        "        api_key=HF_API_KEY,\n",
        "        model_name=model_name,\n",
        "        use_serverless=True  # Start with serverless API\n",
        "    )\n",
        "\n",
        "    # Prepare results storage\n",
        "    predictions = []\n",
        "    ground_truth_relevance = []\n",
        "    predicted_relevance = []\n",
        "    ground_truth_gs_paper = []\n",
        "    predicted_gs_paper = []\n",
        "    confidences = []\n",
        "\n",
        "    print(f\"\\nüîÑ Starting evaluation on {len(df)} samples...\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Evaluate each sample\n",
        "    for idx, row in df.iterrows():\n",
        "        print(f\"\\n[{idx+1}/{len(df)}] Processing ID: {row['ID']}\")\n",
        "\n",
        "        # Get prediction from model\n",
        "        result = evaluator.call_qwen_student(row['Text Chunk'])\n",
        "\n",
        "        # Ground truth\n",
        "        gt_relevant = row['Relevant to UPSC']\n",
        "        gt_gs_paper = row['GS Paper'] if gt_relevant else \"Not Applicable\"\n",
        "\n",
        "        # Prediction\n",
        "        pred_relevant = result['relevant']\n",
        "        pred_gs_paper = result['gs_paper']\n",
        "        confidence = result.get('confidence', 0.0)\n",
        "\n",
        "        # Store results\n",
        "        predictions.append({\n",
        "            'ID': row['ID'],\n",
        "            'Source_PDF': row['Source PDF'],\n",
        "            'Ground_Truth_Relevant': gt_relevant,\n",
        "            'Predicted_Relevant': pred_relevant,\n",
        "            'Ground_Truth_GS_Paper': gt_gs_paper,\n",
        "            'Predicted_GS_Paper': pred_gs_paper,\n",
        "            'Confidence': confidence,\n",
        "            'Correct_Relevance': gt_relevant == pred_relevant,\n",
        "            'Correct_GS_Paper': gt_gs_paper == pred_gs_paper if gt_relevant and pred_relevant else False\n",
        "        })\n",
        "\n",
        "        ground_truth_relevance.append(gt_relevant)\n",
        "        predicted_relevance.append(pred_relevant)\n",
        "        ground_truth_gs_paper.append(gt_gs_paper)\n",
        "        predicted_gs_paper.append(pred_gs_paper)\n",
        "        confidences.append(confidence)\n",
        "\n",
        "        # Progress indicator\n",
        "        match_relevance = \"‚úì\" if gt_relevant == pred_relevant else \"‚úó\"\n",
        "        match_paper = \"‚úì\" if gt_gs_paper == pred_gs_paper else \"‚úó\"\n",
        "        print(f\"  Ground Truth: Relevant={gt_relevant}, Paper={gt_gs_paper}\")\n",
        "        print(f\"  Prediction:   Relevant={pred_relevant}, Paper={pred_gs_paper}\")\n",
        "        print(f\"  Match: Relevance {match_relevance} | GS Paper {match_paper} | Confidence: {confidence:.3f}\")\n",
        "\n",
        "        # Rate limiting - serverless API needs more time\n",
        "        time.sleep(2.0)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    # Create results DataFrame\n",
        "    df_results = pd.DataFrame(predictions)\n",
        "\n",
        "    # Calculate metrics\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üìà EVALUATION RESULTS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Relevance classification metrics\n",
        "    relevance_metrics = calculate_metrics(\n",
        "        ground_truth_relevance,\n",
        "        predicted_relevance,\n",
        "        \"Relevance Classification\"\n",
        "    )\n",
        "\n",
        "    # GS Paper classification metrics (only for relevant items)\n",
        "    relevant_mask = [gt and pred for gt, pred in zip(ground_truth_relevance, predicted_relevance)]\n",
        "    if sum(relevant_mask) > 0:\n",
        "        gs_paper_gt_filtered = [gt for gt, mask in zip(ground_truth_gs_paper, relevant_mask) if mask]\n",
        "        gs_paper_pred_filtered = [pred for pred, mask in zip(predicted_gs_paper, relevant_mask) if mask]\n",
        "\n",
        "        # Convert to binary for metrics (correct paper vs incorrect)\n",
        "        gs_paper_binary_gt = [1] * len(gs_paper_gt_filtered)\n",
        "        gs_paper_binary_pred = [1 if gt == pred else 0\n",
        "                                for gt, pred in zip(gs_paper_gt_filtered, gs_paper_pred_filtered)]\n",
        "\n",
        "        gs_paper_accuracy = sum(gs_paper_binary_pred) / len(gs_paper_binary_pred) if len(gs_paper_binary_pred) > 0 else 0\n",
        "\n",
        "        print(f\"üìä GS Paper Classification (among relevant items)\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Accuracy: {gs_paper_accuracy:.4f} ({gs_paper_accuracy*100:.2f}%)\")\n",
        "        print(f\"Samples:  {len(gs_paper_binary_pred)}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Summary statistics\n",
        "    print(f\"‚è±Ô∏è  PERFORMANCE SUMMARY\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Total samples:        {len(df)}\")\n",
        "    print(f\"Processing time:      {elapsed_time:.2f} seconds\")\n",
        "    print(f\"Avg time per sample:  {elapsed_time/len(df):.2f} seconds\")\n",
        "    print(f\"Avg confidence:       {np.mean(confidences):.3f}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Breakdown by GS Paper\n",
        "    print(f\"üìö BREAKDOWN BY GS PAPER\")\n",
        "    print(f\"{'='*60}\")\n",
        "    for paper in ['GS1', 'GS2', 'GS3', 'GS4']:\n",
        "        paper_df = df_results[df_results['Ground_Truth_GS_Paper'] == paper]\n",
        "        if len(paper_df) > 0:\n",
        "            correct = (paper_df['Ground_Truth_GS_Paper'] == paper_df['Predicted_GS_Paper']).sum()\n",
        "            accuracy = correct / len(paper_df)\n",
        "            print(f\"{paper}: {correct}/{len(paper_df)} correct ({accuracy*100:.1f}%)\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Save results\n",
        "    output_csv = f\"qwen1.5b_student_results_{time.strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "    df_results.to_csv(output_csv, index=False)\n",
        "    print(f\"üíæ Detailed results saved: {output_csv}\")\n",
        "\n",
        "    # Generate visualizations\n",
        "    print(f\"\\nüìä Generating visualizations...\")\n",
        "    plot_confusion_matrix(\n",
        "        relevance_metrics['confusion_matrix'],\n",
        "        'Qwen2.5-1.5B: Relevance Classification Confusion Matrix',\n",
        "        'confusion_matrix_relevance_student.png'\n",
        "    )\n",
        "\n",
        "    plot_gs_paper_accuracy(\n",
        "        df_results,\n",
        "        'gs_paper_accuracy_student.png'\n",
        "    )\n",
        "\n",
        "    # Save metrics summary\n",
        "    metrics_summary = {\n",
        "        'model': model_name,\n",
        "        'total_samples': len(df),\n",
        "        'processing_time_seconds': elapsed_time,\n",
        "        'relevance_accuracy': float(relevance_metrics['accuracy']),\n",
        "        'relevance_precision': float(relevance_metrics['precision']),\n",
        "        'relevance_recall': float(relevance_metrics['recall']),\n",
        "        'relevance_f1': float(relevance_metrics['f1_score']),\n",
        "        'avg_confidence': float(np.mean(confidences)),\n",
        "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "    }\n",
        "\n",
        "    metrics_file = f\"qwen1.5b_metrics_{time.strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    with open(metrics_file, 'w') as f:\n",
        "        json.dump(metrics_summary, f, indent=2)\n",
        "\n",
        "    print(f\"‚úì Metrics summary saved: {metrics_file}\")\n",
        "\n",
        "    # Generate comparison with teacher model if available\n",
        "    if teacher_metrics_file:\n",
        "        plot_comparison_with_teacher(metrics_summary, teacher_metrics_file)\n",
        "\n",
        "    # Download all files\n",
        "    print(f\"\\nüì• Downloading results...\")\n",
        "    files.download(output_csv)\n",
        "    files.download(metrics_file)\n",
        "    files.download('confusion_matrix_relevance_student.png')\n",
        "    files.download('gs_paper_accuracy_student.png')\n",
        "    if teacher_metrics_file:\n",
        "        try:\n",
        "            files.download('teacher_vs_student_comparison.png')\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"‚úÖ TESTING COMPLETE!\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    return df_results, metrics_summary\n",
        "\n",
        "# --- MAIN EXECUTION ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\nüì§ Upload your UPSC dataset CSV file (with ground truth labels)\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"\\n‚ùå No file uploaded. Exiting...\")\n",
        "    else:\n",
        "        csv_file = list(uploaded.keys())[0]\n",
        "        print(f\"\\n‚úì File uploaded: {csv_file}\")\n",
        "\n",
        "        # Ask for sample size\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"‚öôÔ∏è  CONFIGURATION\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"How many samples do you want to test?\")\n",
        "        print(\"  - Enter a number (e.g., 100) for testing subset\")\n",
        "        print(\"  - Press Enter to test ALL samples\")\n",
        "        print(\"-\"*80)\n",
        "\n",
        "        sample_input = input(\"Sample size: \").strip()\n",
        "        sample_size = int(sample_input) if sample_input.isdigit() else None\n",
        "\n",
        "        # Ask for teacher metrics file for comparison\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Do you have teacher model metrics for comparison?\")\n",
        "        print(\"  - Enter the filename (e.g., qwen72b_metrics_20260215_173746.json)\")\n",
        "        print(\"  - Press Enter to skip comparison\")\n",
        "        print(\"-\"*80)\n",
        "\n",
        "        teacher_file = input(\"Teacher metrics file: \").strip()\n",
        "        teacher_metrics_file = teacher_file if teacher_file else None\n",
        "\n",
        "        # Model selection\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"‚öôÔ∏è  MODEL SELECTION\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"Select model to test:\")\n",
        "        print(\"  1. Qwen/Qwen2.5-1.5B-Instruct (default)\")\n",
        "        print(\"  2. Qwen/Qwen2.5-3B-Instruct (more available)\")\n",
        "        print(\"  3. meta-llama/Llama-3.2-1B-Instruct (alternative)\")\n",
        "        print(\"  Press Enter for default (1.5B)\")\n",
        "        print(\"-\"*80)\n",
        "\n",
        "        model_choice = input(\"Model choice (1-3): \").strip()\n",
        "\n",
        "        if model_choice == \"2\":\n",
        "            selected_model = \"Qwen/Qwen2.5-3B-Instruct\"\n",
        "        elif model_choice == \"3\":\n",
        "            selected_model = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "        else:\n",
        "            selected_model = STUDENT_MODEL\n",
        "\n",
        "        print(f\"\\n‚úì Selected model: {selected_model}\")\n",
        "\n",
        "        # Run evaluation\n",
        "        results_df, metrics = test_student_model(csv_file, sample_size, teacher_metrics_file, selected_model)\n",
        "\n",
        "        print(\"\\nüéâ Student model evaluation complete!\")\n",
        "        print(\"üí° Use these results to assess knowledge distillation effectiveness\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VTk9dkDyfS25",
        "outputId": "6d26f0c9-5e5d-41cf-861a-cf30f088cc40"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì§ Upload your UPSC dataset CSV file (with ground truth labels)\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5be85ff4-75b4-4549-af78-02841cef82cf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5be85ff4-75b4-4549-af78-02841cef82cf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving upsc_dataset_langchain_20260213_095213.csv to upsc_dataset_langchain_20260213_095213 (4).csv\n",
            "\n",
            "‚úì File uploaded: upsc_dataset_langchain_20260213_095213 (4).csv\n",
            "\n",
            "================================================================================\n",
            "‚öôÔ∏è  CONFIGURATION\n",
            "================================================================================\n",
            "How many samples do you want to test?\n",
            "  - Enter a number (e.g., 100) for testing subset\n",
            "  - Press Enter to test ALL samples\n",
            "--------------------------------------------------------------------------------\n",
            "Sample size: 30\n",
            "\n",
            "================================================================================\n",
            "Do you have teacher model metrics for comparison?\n",
            "  - Enter the filename (e.g., qwen72b_metrics_20260215_173746.json)\n",
            "  - Press Enter to skip comparison\n",
            "--------------------------------------------------------------------------------\n",
            "Teacher metrics file: \n",
            "\n",
            "================================================================================\n",
            "‚öôÔ∏è  MODEL SELECTION\n",
            "================================================================================\n",
            "Select model to test:\n",
            "  1. Qwen/Qwen2.5-1.5B-Instruct (default)\n",
            "  2. Qwen/Qwen2.5-3B-Instruct (more available)\n",
            "  3. meta-llama/Llama-3.2-1B-Instruct (alternative)\n",
            "  Press Enter for default (1.5B)\n",
            "--------------------------------------------------------------------------------\n",
            "Model choice (1-3): 3\n",
            "\n",
            "‚úì Selected model: meta-llama/Llama-3.2-1B-Instruct\n",
            "================================================================================\n",
            "                    QWEN2.5-1.5B STUDENT MODEL TESTING\n",
            "================================================================================\n",
            "\n",
            "üìÇ Loading dataset...\n",
            "‚úì Loaded 447 rows from upsc_dataset_langchain_20260213_095213 (4).csv\n",
            "‚úì Sampled 30 rows for testing\n",
            "\n",
            "ü§ñ Initializing meta-llama/Llama-3.2-1B-Instruct evaluator...\n",
            "‚úì Using HuggingFace Serverless API: meta-llama/Llama-3.2-1B-Instruct\n",
            "\n",
            "üîÑ Starting evaluation on 30 samples...\n",
            "================================================================================\n",
            "\n",
            "[285/30] Processing ID: UPSC_0244_1_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[378/30] Processing ID: UPSC_0320_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[118/30] Processing ID: UPSC_0108_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=True, Paper=GS2\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úó | GS Paper ‚úó | Confidence: 0.000\n",
            "\n",
            "[389/30] Processing ID: UPSC_0330_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[71/30] Processing ID: UPSC_0070_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[31/30] Processing ID: UPSC_0030_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[193/30] Processing ID: UPSC_0165_1_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[80/30] Processing ID: UPSC_0079_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[363/30] Processing ID: UPSC_0309_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[337/30] Processing ID: UPSC_0284_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=True, Paper=GS2\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úó | GS Paper ‚úó | Confidence: 0.000\n",
            "\n",
            "[56/30] Processing ID: UPSC_0055_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[149/30] Processing ID: UPSC_0134_1_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[369/30] Processing ID: UPSC_0315_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=True, Paper=GS2\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úó | GS Paper ‚úó | Confidence: 0.000\n",
            "\n",
            "[312/30] Processing ID: UPSC_0268_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=True, Paper=GS2\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úó | GS Paper ‚úó | Confidence: 0.000\n",
            "\n",
            "[394/30] Processing ID: UPSC_0335_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[405/30] Processing ID: UPSC_0346_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[76/30] Processing ID: UPSC_0075_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[246/30] Processing ID: UPSC_0213_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=True, Paper=GS3\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úó | GS Paper ‚úó | Confidence: 0.000\n",
            "\n",
            "[365/30] Processing ID: UPSC_0311_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[78/30] Processing ID: UPSC_0077_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[166/30] Processing ID: UPSC_0146_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=True, Paper=GS3\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úó | GS Paper ‚úó | Confidence: 0.000\n",
            "\n",
            "[10/30] Processing ID: UPSC_0009_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[91/30] Processing ID: UPSC_0086_1_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[94/30] Processing ID: UPSC_0089_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[117/30] Processing ID: UPSC_0107_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[298/30] Processing ID: UPSC_0255_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[73/30] Processing ID: UPSC_0072_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[83/30] Processing ID: UPSC_0082_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[212/30] Processing ID: UPSC_0181_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "[40/30] Processing ID: UPSC_0039_0_20260213\n",
            "  ‚ùå API Error 410: {\"error\":\"https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.\"}\n",
            "  Ground Truth: Relevant=False, Paper=Not Applicable\n",
            "  Prediction:   Relevant=False, Paper=Not Applicable\n",
            "  Match: Relevance ‚úì | GS Paper ‚úì | Confidence: 0.000\n",
            "\n",
            "================================================================================\n",
            "üìà EVALUATION RESULTS\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "üìä Relevance Classification Metrics\n",
            "============================================================\n",
            "Accuracy:  0.8000 (80.00%)\n",
            "Precision: 0.0000\n",
            "Recall:    0.0000\n",
            "F1-Score:  0.0000\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted\n",
            "               Neg    Pos\n",
            "Actual Neg      24      0\n",
            "       Pos       6      0\n",
            "============================================================\n",
            "\n",
            "‚è±Ô∏è  PERFORMANCE SUMMARY\n",
            "============================================================\n",
            "Total samples:        30\n",
            "Processing time:      62.75 seconds\n",
            "Avg time per sample:  2.09 seconds\n",
            "Avg confidence:       0.000\n",
            "============================================================\n",
            "\n",
            "üìö BREAKDOWN BY GS PAPER\n",
            "============================================================\n",
            "GS2: 0/4 correct (0.0%)\n",
            "GS3: 0/2 correct (0.0%)\n",
            "============================================================\n",
            "\n",
            "üíæ Detailed results saved: qwen1.5b_student_results_20260215_181659.csv\n",
            "\n",
            "üìä Generating visualizations...\n",
            "‚úì Saved confusion matrix: confusion_matrix_relevance_student.png\n",
            "‚úì Saved GS Paper accuracy plot: gs_paper_accuracy_student.png\n",
            "‚úì Metrics summary saved: qwen1.5b_metrics_20260215_181700.json\n",
            "\n",
            "üì• Downloading results...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7e1b3517-350c-4553-95de-2a599cf1660b\", \"qwen1.5b_student_results_20260215_181659.csv\", 3487)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c67c3f83-ffcf-4eaf-a947-1aa4b5b4d60a\", \"qwen1.5b_metrics_20260215_181700.json\", 291)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6bae01f0-fdea-49b7-ad89-06bfc24d660e\", \"confusion_matrix_relevance_student.png\", 88583)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b225bbba-59ea-4b2f-acde-399fcb1f3076\", \"gs_paper_accuracy_student.png\", 114279)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "‚úÖ TESTING COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "üéâ Student model evaluation complete!\n",
            "üí° Use these results to assess knowledge distillation effectiveness\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "TEACHER_ID = \"Qwen/Qwen2.5-72B-Instruct\" # Or a quantized version for Colab\n",
        "STUDENT_ID = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "TEMPERATURE = 2.0  # Softens the logit distribution\n",
        "ALPHA = 0.5        # Weighting between Distillation and Student loss\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class DistillationTrainer:\n",
        "    def __init__(self, teacher_model, student_model):\n",
        "        self.teacher = teacher_model.to(DEVICE).eval()\n",
        "        self.student = student_model.to(DEVICE).train()\n",
        "\n",
        "    def distillation_loss(self, student_logits, teacher_logits, labels):\n",
        "        # 1. Soft Targets (KL Divergence)\n",
        "        # We divide by T (Temperature) to smooth the probability distribution\n",
        "        soft_targets = F.softmax(teacher_logits / TEMPERATURE, dim=-1)\n",
        "        soft_prob = F.log_softmax(student_logits / TEMPERATURE, dim=-1)\n",
        "\n",
        "        # KL Divergence loss multiplied by T^2 as per original Hinton paper\n",
        "        distill_loss = F.kl_div(soft_prob, soft_targets, reduction='batchmean') * (TEMPERATURE**2)\n",
        "\n",
        "        # 2. Hard Targets (Standard Cross-Entropy)\n",
        "        student_loss = F.cross_entropy(student_logits.view(-1, student_logits.size(-1)), labels.view(-1))\n",
        "\n",
        "        # Weighted Total Loss\n",
        "        return (ALPHA * distill_loss) + ((1 - ALPHA) * student_loss)\n",
        "\n",
        "# --- DATA PREPARATION ---\n",
        "class GoldenDataset(Dataset):\n",
        "    def __init__(self, csv_file, tokenizer, max_length=512):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self): return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.df.iloc[idx]['Text Chunk']\n",
        "        inputs = self.tokenizer(text, truncation=True, padding='max_length',\n",
        "                                max_length=self.max_length, return_tensors=\"pt\")\n",
        "        return inputs.input_ids.squeeze(), inputs.attention_mask.squeeze()\n",
        "\n",
        "# --- TRAINING LOOP ---\n",
        "def train_step(batch, trainer, optimizer):\n",
        "    input_ids, attention_mask = [b.to(DEVICE) for b in batch]\n",
        "\n",
        "    # Get Teacher Logits (No Gradient)\n",
        "    with torch.no_grad():\n",
        "        teacher_outputs = trainer.teacher(input_ids, attention_mask=attention_mask)\n",
        "        teacher_logits = teacher_outputs.logits\n",
        "\n",
        "    # Get Student Logits\n",
        "    student_outputs = trainer.student(input_ids, attention_mask=attention_mask)\n",
        "    student_logits = student_outputs.logits\n",
        "\n",
        "    # Calculate Distillation Loss\n",
        "    loss = trainer.distillation_loss(student_logits, teacher_logits, input_ids)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    return loss.item()\n",
        "\n",
        "# Usage Example:\n",
        "# tokenizer = AutoTokenizer.from_pretrained(STUDENT_ID)\n",
        "# student_model = AutoModelForCausalLM.from_pretrained(STUDENT_ID)\n",
        "# teacher_model = AutoModelForCausalLM.from_pretrained(TEACHER_ID, load_in_4bit=True)\n",
        "# trainer = DistillationTrainer(teacher_model, student_model)"
      ],
      "metadata": {
        "id": "C1NR7IZrvGXO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}